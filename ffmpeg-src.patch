diff -pruN generated/org/ffmpeg/avcodec/AvcodecLibrary.java src/org/ffmpeg/avcodec/AvcodecLibrary.java
--- generated/org/ffmpeg/avcodec/AvcodecLibrary.java	2014-04-13 17:23:16.173679121 +0200
+++ src/org/ffmpeg/avcodec/AvcodecLibrary.java	2014-04-13 17:24:07.044555385 +0200
@@ -1743,11 +1743,11 @@ public class AvcodecLibrary {
 	 * Original signature : <code>AVFrame* avcodec_alloc_frame()</code><br>
 	 * <i>native declaration : ./libavcodec/avcodec.h:419</i>
 	 */
-	public static Pointer<AVFrame > avcodec_alloc_frame() {
-		return Pointer.pointerToAddress(avcodec_alloc_frame$2(), AVFrame.class);
+	public static Pointer<AVFrame > alloc_frame() {
+		return Pointer.pointerToAddress(avcodec_alloc_frame(), AVFrame.class);
 	}
 	@Ptr 
-	protected native static long avcodec_alloc_frame$2();
+	protected native static long avcodec_alloc_frame();
 	/**
 	 * Original signature : <code>int avcodec_open2(AVCodecContext*, const AVCodec*, AVDictionary**)</code><br>
 	 * <i>native declaration : ./libavcodec/avcodec.h:421</i>
diff -pruN generated/org/ffmpeg/avformat/AvformatLibrary.java src/org/ffmpeg/avformat/AvformatLibrary.java
--- generated/org/ffmpeg/avformat/AvformatLibrary.java	2014-04-13 17:23:16.637677992 +0200
+++ src/org/ffmpeg/avformat/AvformatLibrary.java	2014-04-13 17:24:07.044555385 +0200
@@ -319,11 +319,11 @@ public class AvformatLibrary {
 	 * Original signature : <code>AVFormatContext* avformat_alloc_context()</code><br>
 	 * <i>native declaration : libavformat/avformat.h:207</i>
 	 */
-	public static Pointer<AVFormatContext > avformat_alloc_context() {
-		return Pointer.pointerToAddress(avformat_alloc_context$2(), AVFormatContext.class);
+	public static Pointer<AVFormatContext > alloc_context() {
+		return Pointer.pointerToAddress(avformat_alloc_context(), AVFormatContext.class);
 	}
 	@Ptr 
-	protected native static long avformat_alloc_context$2();
+	protected native static long avformat_alloc_context();
 	/**
 	 * Original signature : <code>void avformat_free_context(AVFormatContext*)</code><br>
 	 * <i>native declaration : libavformat/avformat.h:209</i>
diff -pruN generated/org/ffmpeg/avutil/AVUtil.java src/org/ffmpeg/avutil/AVUtil.java
--- generated/org/ffmpeg/avutil/AVUtil.java	1970-01-01 01:00:00.000000000 +0100
+++ src/org/ffmpeg/avutil/AVUtil.java	2014-04-13 17:24:07.045555382 +0200
@@ -0,0 +1,44 @@
+package org.ffmpeg.avutil;
+
+public class AVUtil {
+	public static final long AV_NOPTS_VALUE = 0;
+
+	/** Inline-Funktion rational.h */
+	public static double av_q2d(AVRational a) {
+               return a.num() / (double) a.den();
+       }
+
+	public static String av_ts_make_string(long ts) {
+               if (ts == AV_NOPTS_VALUE)
+                       return "NOPTS";
+               else
+                       return Long.toHexString(ts);
+       }
+
+	/**
+	 * Original signaturre : #define av_ts2str(ts)
+	 * av_ts_make_string((char[AV_TS_MAX_STRING_SIZE]){0}, ts)
+	 */
+	public static String av_ts2str(long ts) {
+               return av_ts_make_string(ts);
+       }
+
+	public static String av_ts_make_time_string(long ts,
+                       AVRational tb) {
+               if (ts == AV_NOPTS_VALUE)
+                       return "NOPTS";
+               else {
+                       String s = String.format("%.6g", av_q2d(tb) * ts);
+                       return s;
+               }
+       }
+
+	/**
+	 * Original signature : #define av_ts2timestr(ts, tb)
+	 * av_ts_make_time_string((char[AV_TS_MAX_STRING_SIZE]){0}, ts, tb)
+	 */
+	public static String av_ts2timestr(long ts, AVRational tb) {
+               return av_ts_make_time_string(ts, tb);
+       }
+
+}
diff -pruN generated/org/ffmpeg/avutil/AvutilLibrary.java src/org/ffmpeg/avutil/AvutilLibrary.java
--- generated/org/ffmpeg/avutil/AvutilLibrary.java	2014-04-13 17:23:14.717682663 +0200
+++ src/org/ffmpeg/avutil/AvutilLibrary.java	2014-04-13 17:24:07.046555380 +0200
@@ -801,11 +801,11 @@ public class AvutilLibrary {
 	 * Original signature : <code>void* av_malloc(size_t)</code><br>
 	 * <i>native declaration : libavutil/mem.h:1</i>
 	 */
-	public static Pointer<? > av_malloc(@CLong long size) {
-		return Pointer.pointerToAddress(av_malloc$2(size));
+	public static Pointer<? > malloc(@CLong long size) {
+		return Pointer.pointerToAddress(av_malloc(size));
 	}
 	@Ptr 
-	protected native static long av_malloc$2(@CLong long size);
+	protected native static long av_malloc(@CLong long size);
 	/**
 	 * Original signature : <code>void av_free(void*)</code><br>
 	 * <i>native declaration : libavutil/mem.h:3</i>
diff -pruN generated/org/ffmpeg/FFMPeg.java src/org/ffmpeg/FFMPeg.java
--- generated/org/ffmpeg/FFMPeg.java	1970-01-01 01:00:00.000000000 +0100
+++ src/org/ffmpeg/FFMPeg.java	2014-04-13 17:24:07.046555380 +0200
@@ -0,0 +1,28 @@
+package org.ffmpeg;
+
+import org.ffmpeg.avcodec.AvcodecLibrary;
+import org.ffmpeg.avformat.AvformatLibrary;
+import org.ffmpeg.avutil.AvutilLibrary;
+
+public class FFMPeg {
+
+	private static AvcodecLibrary avc;
+	private static AvutilLibrary avu;
+	private static AvformatLibrary avf;
+	
+	public static void main(String[] args) {
+		System.out.println("Java-Bibliothek ffmpeg.jar");
+		System.out.println("==========================");
+		System.out.println("Die Bibliothek ffmpeg ist nur in den Bruchteilen implementiert, die für\n"
+				+ "Open Source Physics tracker benötigt werden.");
+		System.out.println("Bestandteile:");
+		avc = new AvcodecLibrary();
+		avu = new AvutilLibrary();
+		avf = new AvformatLibrary();
+		System.out.println("avutil in Version "+avu.avutil_version());
+		System.out.println("avcodec in Version "+avc.avcodec_version());
+		System.out.println("avformat in Version "+avf.avformat_version());
+		System.out.println("swscale in Version ");
+	}
+	
+}
diff -pruN generated/test/AVInfo.java src/test/AVInfo.java
--- generated/test/AVInfo.java	1970-01-01 01:00:00.000000000 +0100
+++ src/test/AVInfo.java	2014-04-06 19:13:30.278248583 +0200
@@ -0,0 +1,64 @@
+package test;
+
+import static org.ffmpeg.avformat.AvformatLibrary.av_dump_format;
+import static org.ffmpeg.avformat.AvformatLibrary.av_register_all;
+import static org.ffmpeg.avformat.AvformatLibrary.avformat_close_input;
+import static org.ffmpeg.avformat.AvformatLibrary.avformat_open_input;
+
+import java.io.IOException;
+
+import org.bridj.Pointer;
+import org.ffmpeg.avformat.AVFormatContext;
+import org.ffmpeg.avformat.AVStream;
+
+public class AVInfo {
+	public static String src_filename;
+	public static Pointer<AVFormatContext> fmt_ctx;
+	public static Pointer<AVStream> stream;
+	
+	public static void main(String[] args) {
+		int ret = 0;
+
+		if (args.length != 1) {
+			System.err.printf("usage: AVInfo input_file \n"
+					+ "API example program to show input file infos.\n" + "\n");
+			System.exit(1);
+		}
+		src_filename = args[0];
+		try {
+			/* register all formats and codecs */
+			av_register_all();
+
+			/* open input file, and allocate format context */
+			Pointer<Pointer<AVFormatContext>> pfmt_ctx = Pointer
+					.allocatePointer(AVFormatContext.class);
+			if (avformat_open_input(pfmt_ctx,
+					Pointer.pointerToCString(src_filename), null, null) < 0) {
+				System.err.printf("Could not open source file %s\n",
+						src_filename);
+				System.exit(1);
+			}
+
+			fmt_ctx = pfmt_ctx.get();
+			/* dump input information to stderr */
+			av_dump_format(fmt_ctx, 0, Pointer.pointerToCString(src_filename), 0);
+
+			int streams = fmt_ctx.get().nb_streams();
+			for(int index = 0;index<streams;index++){
+				stream = fmt_ctx.get().streams().get(index);
+				
+			}
+			// } catch (IOException e) {
+			// e.printStackTrace();
+			// System.exit(1);
+		} finally {
+			System.err.print("freeing fmt_ctx...");
+			if (fmt_ctx != null) {
+				avformat_close_input(fmt_ctx.getReference());
+			}
+			System.err.println("freed");
+			System.exit(ret);
+		}
+	}
+
+}
diff -pruN generated/test/Demuxing.java src/test/Demuxing.java
--- generated/test/Demuxing.java	1970-01-01 01:00:00.000000000 +0100
+++ src/test/Demuxing.java	2014-04-07 11:34:27.270173613 +0200
@@ -0,0 +1,385 @@
+package test;
+
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.IntBuffer;
+
+import org.bridj.Pointer;
+import org.ffmpeg.avcodec.AVCodec;
+import org.ffmpeg.avcodec.AVCodecContext;
+import org.ffmpeg.avcodec.AvcodecLibrary;
+import org.ffmpeg.avcodec.AVPacket;
+import org.ffmpeg.avformat.AVFormatContext;
+import org.ffmpeg.avformat.AVStream;
+import org.ffmpeg.avformat.AvformatLibrary;
+import org.ffmpeg.avutil.AVFrame;
+import org.ffmpeg.avutil.AvutilLibrary;
+import org.ffmpeg.avutil.AvutilLibrary.AVMediaType;
+import org.ffmpeg.avutil.AvutilLibrary.AVSampleFormat;
+
+import static org.ffmpeg.avcodec.AvcodecLibrary.*;
+import static org.ffmpeg.avutil.AvutilLibrary.*;
+import static org.ffmpeg.avformat.AvformatLibrary.*;
+import static org.ffmpeg.avutil.AVUtil.*;
+
+/**
+ * @file libavformat demuxing API use example.
+ * 
+ *       Show how to use the libavformat and libavcodec API to demux and decode
+ *       audio and video data.
+ * @example doc/examples/demuxing.c
+ */
+
+public class Demuxing {
+	static Pointer<AVFormatContext> fmt_ctx = null;
+	static Pointer<AVCodecContext> video_dec_ctx = null, audio_dec_ctx;
+	static Pointer<AVStream> video_stream = null, audio_stream = null;
+	static String src_filename = null;
+	static String video_dst_filename = null;
+	static String audio_dst_filename = null;
+	static FileOutputStream video_dst_file = null;
+	static FileOutputStream audio_dst_file = null;
+
+	static Pointer<Pointer<Byte>> video_dst_data = null;
+	static Pointer<Integer> video_dst_linesize = Pointer.allocateInts(4);
+	static int video_dst_bufsize;
+
+	static Pointer<Integer> video_stream_idx = Pointer.allocateInt(), 
+			audio_stream_idx = Pointer.allocateInt();
+	static Pointer<AVFrame> frame = null;
+	static Pointer<AVPacket> pkt = null;
+	static int video_frame_count = 0;
+	static int audio_frame_count = 0;
+	static AvformatLibrary lavf = new AvformatLibrary();
+	static AvcodecLibrary lavc = new AvcodecLibrary();
+	static AvutilLibrary lavu = new AvutilLibrary();
+
+	static int decode_packet(Pointer<Integer> got_frame, int cached)
+			throws IOException {
+		int ret = 0;
+		int decoded = pkt.get().size();
+
+		if (pkt.get().stream_index() == video_stream_idx.get()) {
+			/* decode video frame */
+			ret = avcodec_decode_video2(video_dec_ctx, frame, got_frame,
+					pkt);
+			if (ret < 0) {
+				System.err.printf("Error decoding video frame\n");
+				return ret;
+			}
+
+			if (got_frame.get() != 0) {
+				System.out.printf("video_frame%s n:%d coded_n:%d pts:%s\n",
+						cached != 0 ? "(cached)" : "", video_frame_count++,
+						frame.get().coded_picture_number(), av_ts2timestr(
+								frame.get().pts(), video_dec_ctx.get().time_base()));
+
+				/*
+				 * copy decoded frame to destination buffer: this is required
+				 * since rawvideo expects non aligned data
+				 */
+				av_image_copy(video_dst_data, video_dst_linesize,
+						frame.get().data(), frame.get().linesize(), video_dec_ctx.get().pix_fmt(),
+						video_dec_ctx.get().width(), video_dec_ctx.get().height());
+
+				/* write to rawvideo file */
+				video_dst_file.write(video_dst_data.getBytes());
+			}
+		} else if (pkt.get().stream_index() == audio_stream_idx.get()) {
+			/* decode audio frame */
+			ret = avcodec_decode_audio4(audio_dec_ctx, frame, got_frame,
+					pkt);
+			if (ret < 0) {
+				System.err.printf("Error decoding audio frame\n");
+				return ret;
+			}
+			/*
+			 * Some audio decoders decode only part of the packet, and have to
+			 * be called again with the remainder of the packet data. Sample:
+			 * fate-suite/lossless-audio/luckynight-partial.shn Also, some
+			 * decoders might over-read the packet.
+			 */
+			decoded = Math.min(ret, pkt.get().size());
+
+			if (got_frame.get() != 0) {
+				int unpadded_linesize = frame.get().nb_samples()
+						* av_get_bytes_per_sample(AVSampleFormat.fromValue(frame.get().format()));
+				System.out.printf("audio_frame%s n:%d nb_samples:%d pts:%s\n",
+						cached != 0 ? "(cached)" : "", audio_frame_count++,
+						frame.get().nb_samples(), av_ts2timestr(frame.get().pts(),
+								audio_dec_ctx.get().time_base()));
+
+				/*
+				 * Write the raw audio data samples of the first plane. This
+				 * works fine for packed formats (e.g. AV_SAMPLE_FMT_S16).
+				 * However, most audio decoders output planar audio, which uses
+				 * a separate plane of audio samples for each channel (e.g.
+				 * AV_SAMPLE_FMT_S16P). In other words, this code will write
+				 * only the first audio channel in these cases. You should use
+				 * libswresample or libavfilter to convert the frame to packed
+				 * data.
+				 */
+				audio_dst_file.write(frame.get().extended_data().getBytes(unpadded_linesize));
+			}
+		}
+
+		return decoded;
+	}
+
+	static int open_codec_context(Pointer<Integer> stream_idx,
+			Pointer<AVFormatContext> fmt_ctx, AVMediaType type) {
+		int ret;
+		Pointer<AVStream> st;
+		Pointer<AVCodecContext> dec_ctx = null;
+		Pointer<AVCodec> dec = null;
+
+		ret = av_find_best_stream(fmt_ctx, type, -1, -1, null, 0);
+		if (ret < 0) {
+			System.err.printf("Could not find %s stream in input file '%s'\n",
+					av_get_media_type_string(type).getCString(), src_filename);
+			return ret;
+		} else {
+			stream_idx.set(ret);
+			st = fmt_ctx.get().streams().get(stream_idx.get());
+
+			/* find decoder for the stream */
+			dec_ctx = st.get().codec();
+			dec = avcodec_find_decoder(dec_ctx.get().codec_id());
+			if (dec == null) {
+				System.err.printf("Failed to find %s codec\n",
+						av_get_media_type_string(type));
+				return ret;
+			}
+
+			if ((ret = avcodec_open2(dec_ctx, dec, null)) < 0) {
+				System.err.printf("Failed to open %s codec\n",
+						av_get_media_type_string(type));
+				return ret;
+			}
+		}
+
+		return 0;
+	}
+
+	static String get_format_from_sample_fmt(AVSampleFormat sample_fmt) {
+		switch (sample_fmt) {
+		case AV_SAMPLE_FMT_U8:
+			return "u8";
+		case AV_SAMPLE_FMT_S16:
+			return "s16le";
+		case AV_SAMPLE_FMT_S32:
+			return "s32le";
+		case AV_SAMPLE_FMT_FLT:
+			return "f32le";
+		case AV_SAMPLE_FMT_DBL:
+			return "f64le";
+		default:
+			break;
+		}
+		System.err.printf(
+				"sample format %s is not supported as output format\n",
+				av_get_sample_fmt_name(sample_fmt));
+		return null;
+	}
+
+	public static void main(String[] args) throws IOException {
+		int ret = 0;
+		Pointer<Integer> got_frame = Pointer.allocateInt();
+		video_stream_idx.set(-1);
+		audio_stream_idx.set(-1);
+		if (args.length != 3) {
+			System.err
+					.printf("usage: Demuxing input_file video_output_file audio_output_file\n"
+							+ "API example program to show how to read frames from an input file.\n"
+							+ "This program reads frames from a file, decodes them, and writes decoded\n"
+							+ "video frames to a rawvideo file named video_output_file, and decoded\n"
+							+ "audio frames to a rawaudio file named audio_output_file.\n"
+							+ "\n");
+			System.exit(1);
+		}
+		src_filename = args[0];
+		video_dst_filename = args[1];
+		audio_dst_filename = args[2];
+
+		try {
+			/* register all formats and codecs */
+			av_register_all();
+
+			/* open input file, and allocate format context */
+			Pointer<Pointer<AVFormatContext>> pfmt_ctx = Pointer.allocatePointer(AVFormatContext.class);
+			if (avformat_open_input(pfmt_ctx, Pointer.pointerToCString(src_filename), null, null) < 0) {
+				System.err.printf("Could not open source file %s\n",
+						src_filename);
+				System.exit(1);
+			}
+
+			fmt_ctx = pfmt_ctx.get();
+			/* retrieve stream information */
+			if (avformat_find_stream_info(fmt_ctx, null) < 0) {
+				System.err.printf("Could not find stream information\n");
+				System.exit(1);
+			}
+			
+			if (open_codec_context(video_stream_idx, fmt_ctx,
+					AVMediaType.AVMEDIA_TYPE_VIDEO) >= 0) {
+				video_stream = fmt_ctx.get().streams().get(video_stream_idx.get());
+				video_dec_ctx = video_stream.get().codec();
+
+				try {
+					video_dst_file = new FileOutputStream(video_dst_filename);
+				} catch (IOException e) {
+					System.err.printf("Could not open destination file %s\n",
+							video_dst_filename);
+					ret = 1;
+					System.exit(1);
+				}
+
+				/* allocate image where the decoded image will be put */
+				ret = av_image_alloc(video_dst_data, video_dst_linesize,
+						video_dec_ctx.get().width(), video_dec_ctx.get().height(),
+						video_dec_ctx.get().pix_fmt(), 1);
+				if (ret < 0) {
+					System.err.printf("Could not allocate raw video buffer\n");
+					System.exit(ret);
+				}
+				video_dst_bufsize = ret;
+			}
+
+			if (open_codec_context(audio_stream_idx, fmt_ctx,
+					AVMediaType.AVMEDIA_TYPE_AUDIO) >= 0) {
+				audio_stream = fmt_ctx.get().streams().get(audio_stream_idx.get());
+				audio_dec_ctx = audio_stream.get().codec();
+				try {
+					audio_dst_file = new FileOutputStream(audio_dst_filename);
+				} catch (IOException e) {
+					System.err.printf("Could not open destination file %s\n",
+							video_dst_filename);
+					System.exit(1);
+				}
+			}
+
+			/* dump input information to stderr */
+			av_dump_format(fmt_ctx, 0, Pointer.pointerToCString(src_filename), 0);
+
+			if (audio_stream == null && video_stream == null) {
+				System.err
+						.printf("Could not find audio or video stream in the input, aborting\n");
+				System.exit(1);
+			}
+
+			frame = alloc_frame();
+			if (frame == null) {
+				System.err.printf("Could not allocate frame\n");
+				System.exit(1);
+			}
+
+			/* initialize packet, set data to null, let the demuxer fill it */
+			pkt = Pointer.allocate(AVPacket.class);
+			av_init_packet(pkt);
+			pkt.get().data(null);
+			pkt.get().size(0);
+
+			if (video_stream != null)
+				System.out.printf("Demuxing video from file '%s' into '%s'\n",
+						src_filename, video_dst_filename);
+			if (audio_stream != null)
+				System.out.printf("Demuxing audio from file '%s' into '%s'\n",
+						src_filename, audio_dst_filename);
+
+			/* read frames from the file */
+			while (av_read_frame(fmt_ctx, pkt) >= 0) {
+				Pointer<AVPacket> orig_pkt = pkt;
+				do {
+					System.err.println("decode_packet");
+					ret = decode_packet(got_frame, 0);
+					if (ret < 0)
+						break;
+					System.err.println("modify data ptr");
+					long ptr = pkt.get().data().getPeer();
+					ptr+=ret;
+					pkt.get().data((Pointer<Byte>)Pointer.pointerToAddress(ptr));
+					pkt.get().size(pkt.get().size()-ret);
+					System.err.println("modify data ptr completed");
+				} while (pkt.get().size() > 0);
+				System.err.println("av_free_packet");
+				av_free_packet(orig_pkt);
+				System.err.println("av_free_packet completed");
+			}
+
+			/* flush cached frames */
+			pkt.get().data(null);
+			pkt.get().size(0);
+			do {
+				decode_packet(got_frame, 1);
+			} while (got_frame.get() != 0);
+
+			System.out.printf("Demuxing succeeded.\n");
+
+			if (video_stream != null) {
+				System.out
+						.printf("Play the output video file with the command:\n"
+								+ "ffplay -f rawvideo -pix_fmt %s -video_size %dx%d %s\n",
+								av_get_pix_fmt_name(video_dec_ctx.get().pix_fmt()),
+								video_dec_ctx.get().width(), video_dec_ctx.get().height(),
+								video_dst_filename);
+			}
+
+			if (audio_stream != null) {
+				AVSampleFormat sfmt = (AVSampleFormat) audio_dec_ctx.get().sample_fmt();
+				int n_channels = audio_dec_ctx.get().channels();
+				String fmt;
+
+				if (av_sample_fmt_is_planar(sfmt) != 0) {
+					String packed = av_get_sample_fmt_name(sfmt).getCString();
+					System.out
+							.printf("Warning: the sample format the decoder produced is planar "
+									+ "(%s). This example will output the first channel only.\n",
+									packed != null ? packed : "?");
+					sfmt = (AVSampleFormat) av_get_packed_sample_fmt(sfmt);
+					n_channels = 1;
+				}
+
+				if ((fmt = get_format_from_sample_fmt(sfmt)) == null)
+					System.exit(-1);
+				ret = 0;
+				System.out.printf(
+						"Play the output audio file with the command:\n"
+								+ "ffplay -f %s -ac %d -ar %d %s\n", fmt,
+						n_channels, audio_dec_ctx.get().sample_rate(),
+						audio_dst_filename);
+			}
+
+		} catch (IOException e) {
+			e.printStackTrace();
+			System.exit(1);
+		} finally {
+			System.err.print("freeing video_dec_ctx..");
+			if (video_dec_ctx != null)
+				avcodec_close(video_dec_ctx);
+			System.err.println("freed");
+			System.err.print("freeing audio_dec_ctx...");
+			if (audio_dec_ctx != null)
+				avcodec_close(audio_dec_ctx);
+			System.err.println("freed");
+			System.err.print("freeing fmt_ctx...");
+			if(fmt_ctx != null) {
+				avformat_close_input(fmt_ctx.getReference());
+			}
+			System.err.println("freed");
+			if (video_dst_file != null)
+				video_dst_file.close();
+			if (audio_dst_file != null)
+				audio_dst_file.close();
+			System.err.print("freeing frame...");
+			if(frame != null)
+				av_free(frame);
+			System.err.println("freed");
+			System.err.print("freeing video_dst_data...");
+			if(video_dst_data != null && video_dst_data.getValidElements() > 0)
+				av_freep(video_dst_data);
+			System.err.println("freed");
+		}
+		System.exit(ret);
+	}
+}
