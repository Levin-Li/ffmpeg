package org.ffmpeg.avutil;
import java.util.List;

import org.bridj.BridJ;
import org.bridj.IntValuedEnum;
import org.bridj.Pointer;
import org.bridj.StructFieldDescription;
import org.bridj.StructObject;
import org.bridj.ann.Alignment;
import org.bridj.ann.Array;
import org.bridj.ann.Field;
import org.bridj.ann.Library;
import org.bridj.ann.Struct;
import org.ffmpeg.avcodec.AVCodecContext;
import org.ffmpeg.avcodec.AVPanScan;
import org.ffmpeg.avutil.AvutilLibrary.AVChromaLocation;
import org.ffmpeg.avutil.AvutilLibrary.AVColorPrimaries;
import org.ffmpeg.avutil.AvutilLibrary.AVColorRange;
import org.ffmpeg.avutil.AvutilLibrary.AVColorSpace;
import org.ffmpeg.avutil.AvutilLibrary.AVColorTransferCharacteristic;
import org.ffmpeg.avutil.AvutilLibrary.AVPictureType;
import org.ffmpeg.util.AlignmentCustomizer;
/**
 * <i>native declaration : libavutil/frame.h:376</i><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> or <a href="http://bridj.googlecode.com/">BridJ</a> .
 */
@Library("avutil") 
public class AVFrame extends StructObject {
	static {
		BridJ.register();
	}
	/**
	 * pointer to the picture/channel planes.<br>
	 * This might be different from the first allocated byte<br>
	 * * Some decoders access areas outside 0,0 - width,height, please<br>
	 * see avcodec_align_dimensions2(). Some filters and swscale can read<br>
	 * up to 16 bytes beyond the planes, if these filters are to be used,<br>
	 * then 16 extra bytes must be allocated.<br>
	 * C type : uint8_t*[8]
	 */
	@Array({8}) 
	@Field(0) 
	public Pointer<Pointer<Byte > > data() {
		return this.io.getPointerField(this, 0);
	}
	/**
	 * For video, size in bytes of each picture line.<br>
	 * For audio, size in bytes of each plane.<br>
	 * * For audio, only linesize[0] may be set. For planar audio, each channel<br>
	 * plane must be the same size.<br>
	 * * For video the linesizes should be multiples of the CPUs alignment<br>
	 * preference, this is 16 or 32 for modern desktop CPUs.<br>
	 * Some code requires such alignment other code can be slower without<br>
	 * correct alignment, for yet other it makes no difference.<br>
	 * * @note The linesize may be larger than the size of usable data -- there<br>
	 * may be extra padding present for performance reasons.<br>
	 * C type : int[8]
	 */
	@Array({8}) 
	@Field(1) 
	public Pointer<Integer > linesize() {
		return this.io.getPointerField(this, 1);
	}
	/**
	 * pointers to the data planes/channels.<br>
	 * * For video, this should simply point to data[].<br>
	 * * For planar audio, each channel has a separate data pointer, and<br>
	 * linesize[0] contains the size of each channel buffer.<br>
	 * For packed audio, there is just one data pointer, and linesize[0]<br>
	 * contains the total size of the buffer for all channels.<br>
	 * * Note: Both data and extended_data should always be set in a valid frame,<br>
	 * but for planar audio with more channels that can fit in data,<br>
	 * extended_data must be used in order to access all channels.<br>
	 * C type : uint8_t**
	 */
	@Field(2) 
	public Pointer<Pointer<Byte > > extended_data() {
		return this.io.getPointerField(this, 2);
	}
	/**
	 * pointers to the data planes/channels.<br>
	 * * For video, this should simply point to data[].<br>
	 * * For planar audio, each channel has a separate data pointer, and<br>
	 * linesize[0] contains the size of each channel buffer.<br>
	 * For packed audio, there is just one data pointer, and linesize[0]<br>
	 * contains the total size of the buffer for all channels.<br>
	 * * Note: Both data and extended_data should always be set in a valid frame,<br>
	 * but for planar audio with more channels that can fit in data,<br>
	 * extended_data must be used in order to access all channels.<br>
	 * C type : uint8_t**
	 */
	@Field(2) 
	public AVFrame extended_data(Pointer<Pointer<Byte > > extended_data) {
		this.io.setPointerField(this, 2, extended_data);
		return this;
	}
	/** width and height of the video frame */
	@Field(3) 
	public int width() {
		return this.io.getIntField(this, 3);
	}
	/** width and height of the video frame */
	@Field(3) 
	public AVFrame width(int width) {
		this.io.setIntField(this, 3, width);
		return this;
	}
	/** width and height of the video frame */
	@Field(4) 
	public int height() {
		return this.io.getIntField(this, 4);
	}
	/** width and height of the video frame */
	@Field(4) 
	public AVFrame height(int height) {
		this.io.setIntField(this, 4, height);
		return this;
	}
	/** number of audio samples (per channel) described by this frame */
	@Field(5) 
	public int nb_samples() {
		return this.io.getIntField(this, 5);
	}
	/** number of audio samples (per channel) described by this frame */
	@Field(5) 
	public AVFrame nb_samples(int nb_samples) {
		this.io.setIntField(this, 5, nb_samples);
		return this;
	}
	/**
	 * format of the frame, -1 if unknown or unset<br>
	 * Values correspond to enum AVPixelFormat for video frames,<br>
	 * enum AVSampleFormat for audio)
	 */
	@Field(6) 
	public int format() {
		return this.io.getIntField(this, 6);
	}
	/**
	 * format of the frame, -1 if unknown or unset<br>
	 * Values correspond to enum AVPixelFormat for video frames,<br>
	 * enum AVSampleFormat for audio)
	 */
	@Field(6) 
	public AVFrame format(int format) {
		this.io.setIntField(this, 6, format);
		return this;
	}
	/** 1 -> keyframe, 0-> not */
	@Field(7) 
	public int key_frame() {
		return this.io.getIntField(this, 7);
	}
	/** 1 -> keyframe, 0-> not */
	@Field(7) 
	public AVFrame key_frame(int key_frame) {
		this.io.setIntField(this, 7, key_frame);
		return this;
	}
	/**
	 * Picture type of the frame.<br>
	 * C type : AVPictureType
	 */
	@Field(8) 
	public IntValuedEnum<AVPictureType > pict_type() {
		return this.io.getEnumField(this, 8);
	}
	/**
	 * Picture type of the frame.<br>
	 * C type : AVPictureType
	 */
	@Field(8) 
	public AVFrame pict_type(IntValuedEnum<AVPictureType > pict_type) {
		this.io.setEnumField(this, 8, pict_type);
		return this;
	}
	/** C type : uint8_t*[8] */
	@Array({8}) 
	@Field(9) 
	public Pointer<Pointer<Byte > > base() {
		return this.io.getPointerField(this, 9);
	}
	/**
	 * Sample aspect ratio for the video frame, 0/1 if unknown/unspecified.<br>
	 * C type : AVRational
	 */
	@Field(10) 
	public AVRational sample_aspect_ratio() {
		return this.io.getNativeObjectField(this, 10);
	}
	/**
	 * Sample aspect ratio for the video frame, 0/1 if unknown/unspecified.<br>
	 * C type : AVRational
	 */
	@Field(10) 
	public AVFrame sample_aspect_ratio(AVRational sample_aspect_ratio) {
		this.io.setNativeObjectField(this, 10, sample_aspect_ratio);
		return this;
	}
	/** Presentation timestamp in time_base units (time when frame should be shown to user). */
	@Alignment(4)
	@Field(11) 
	public long pts() {
		return this.io.getLongField(this, 11);
	}
	/** Presentation timestamp in time_base units (time when frame should be shown to user). */
	@Field(11) 
	@Alignment(4)
	public AVFrame pts(long pts) {
		this.io.setLongField(this, 11, pts);
		return this;
	}
	/** PTS copied from the AVPacket that was decoded to produce this frame. */
	@Alignment(4)
	@Field(12) 
	public long pkt_pts() {
		return this.io.getLongField(this, 12);
	}
	/** PTS copied from the AVPacket that was decoded to produce this frame. */
	@Alignment(4)
	@Field(12) 
	public AVFrame pkt_pts(long pkt_pts) {
		this.io.setLongField(this, 12, pkt_pts);
		return this;
	}
	/**
	 * DTS copied from the AVPacket that triggered returning this frame. (if frame threading isn't used)<br>
	 * This is also the Presentation time of this AVFrame calculated from<br>
	 * only AVPacket.dts values without pts values.
	 */
	@Alignment(4)
	@Field(13) 
	public long pkt_dts() {
		return this.io.getLongField(this, 13);
	}
	/**
	 * DTS copied from the AVPacket that triggered returning this frame. (if frame threading isn't used)<br>
	 * This is also the Presentation time of this AVFrame calculated from<br>
	 * only AVPacket.dts values without pts values.
	 */
	@Alignment(4)
	@Field(13) 
	public AVFrame pkt_dts(long pkt_dts) {
		this.io.setLongField(this, 13, pkt_dts);
		return this;
	}
	/** picture number in bitstream order */
	@Field(14) 
	public int coded_picture_number() {
		return this.io.getIntField(this, 14);
	}
	/** picture number in bitstream order */
	@Field(14) 
	public AVFrame coded_picture_number(int coded_picture_number) {
		this.io.setIntField(this, 14, coded_picture_number);
		return this;
	}
	/** picture number in display order */
	@Field(15) 
	public int display_picture_number() {
		return this.io.getIntField(this, 15);
	}
	/** picture number in display order */
	@Field(15) 
	public AVFrame display_picture_number(int display_picture_number) {
		this.io.setIntField(this, 15, display_picture_number);
		return this;
	}
	/** quality (between 1 (good) and FF_LAMBDA_MAX (bad)) */
	@Field(16) 
	public int quality() {
		return this.io.getIntField(this, 16);
	}
	/** quality (between 1 (good) and FF_LAMBDA_MAX (bad)) */
	@Field(16) 
	public AVFrame quality(int quality) {
		this.io.setIntField(this, 16, quality);
		return this;
	}
	@Field(17) 
	public int reference() {
		return this.io.getIntField(this, 17);
	}
	@Field(17) 
	public AVFrame reference(int reference) {
		this.io.setIntField(this, 17, reference);
		return this;
	}
	/**
	 * QP table<br>
	 * C type : int8_t*
	 */
	@Field(18) 
	public Pointer<Byte > qscale_table() {
		return this.io.getPointerField(this, 18);
	}
	/**
	 * QP table<br>
	 * C type : int8_t*
	 */
	@Field(18) 
	public AVFrame qscale_table(Pointer<Byte > qscale_table) {
		this.io.setPointerField(this, 18, qscale_table);
		return this;
	}
	/** QP store stride */
	@Field(19) 
	public int qstride() {
		return this.io.getIntField(this, 19);
	}
	/** QP store stride */
	@Field(19) 
	public AVFrame qstride(int qstride) {
		this.io.setIntField(this, 19, qstride);
		return this;
	}
	@Field(20) 
	public int qscale_type() {
		return this.io.getIntField(this, 20);
	}
	@Field(20) 
	public AVFrame qscale_type(int qscale_type) {
		this.io.setIntField(this, 20, qscale_type);
		return this;
	}
	/**
	 * mbskip_table[mb]>=1 if MB didn't change<br>
	 * stride= mb_width = (width+15)>>4<br>
	 * C type : uint8_t*
	 */
	@Field(21) 
	public Pointer<Byte > mbskip_table() {
		return this.io.getPointerField(this, 21);
	}
	/**
	 * mbskip_table[mb]>=1 if MB didn't change<br>
	 * stride= mb_width = (width+15)>>4<br>
	 * C type : uint8_t*
	 */
	@Field(21) 
	public AVFrame mbskip_table(Pointer<Byte > mbskip_table) {
		this.io.setPointerField(this, 21, mbskip_table);
		return this;
	}
	/**
	 * motion vector table<br>
	 * @code<br>
	 * example:<br>
	 * int mv_sample_log2= 4 - motion_subsample_log2;<br>
	 * int mb_width= (width+15)>>4;<br>
	 * int mv_stride= (mb_width << mv_sample_log2) + 1;<br>
	 * motion_val[direction][x + y*mv_stride][0->mv_x, 1->mv_y];<br>
	 * @endcode<br>
	 * C type : int16_t[2]*[2]
	 */
	@Array({2}) 
	@Field(22) 
	public Pointer<Pointer<Pointer<Short > > > motion_val() {
		return this.io.getPointerField(this, 22);
	}
	/**
	 * macroblock type table<br>
	 * mb_type_base + mb_width + 2<br>
	 * C type : uint32_t*
	 */
	@Field(23) 
	public Pointer<Integer > mb_type() {
		return this.io.getPointerField(this, 23);
	}
	/**
	 * macroblock type table<br>
	 * mb_type_base + mb_width + 2<br>
	 * C type : uint32_t*
	 */
	@Field(23) 
	public AVFrame mb_type(Pointer<Integer > mb_type) {
		this.io.setPointerField(this, 23, mb_type);
		return this;
	}
	/**
	 * DCT coefficients<br>
	 * C type : short*
	 */
	@Field(24) 
	public Pointer<Short > dct_coeff() {
		return this.io.getPointerField(this, 24);
	}
	/**
	 * DCT coefficients<br>
	 * C type : short*
	 */
	@Field(24) 
	public AVFrame dct_coeff(Pointer<Short > dct_coeff) {
		this.io.setPointerField(this, 24, dct_coeff);
		return this;
	}
	/**
	 * motion reference frame index<br>
	 * the order in which these are stored can depend on the codec.<br>
	 * C type : int8_t*[2]
	 */
	@Array({2}) 
	@Field(25) 
	public Pointer<Pointer<Byte > > ref_index() {
		return this.io.getPointerField(this, 25);
	}
	/**
	 * for some private data of the user<br>
	 * C type : void*
	 */
	@Field(26) 
	public Pointer<? > opaque() {
		return this.io.getPointerField(this, 26);
	}
	/**
	 * for some private data of the user<br>
	 * C type : void*
	 */
	@Field(26) 
	public AVFrame opaque(Pointer<? > opaque) {
		this.io.setPointerField(this, 26, opaque);
		return this;
	}
	/**
	 * error<br>
	 * C type : uint64_t[8]
	 */
	@Array({8}) 
	@Field(27) 
	public Pointer<Long > error() {
		return this.io.getPointerField(this, 27);
	}
	@Field(28) 
	public int type() {
		return this.io.getIntField(this, 28);
	}
	@Field(28) 
	public AVFrame type(int type) {
		this.io.setIntField(this, 28, type);
		return this;
	}
	/**
	 * When decoding, this signals how much the picture must be delayed.<br>
	 * extra_delay = repeat_pict / (2*fps)
	 */
	@Field(29) 
	public int repeat_pict() {
		return this.io.getIntField(this, 29);
	}
	/**
	 * When decoding, this signals how much the picture must be delayed.<br>
	 * extra_delay = repeat_pict / (2*fps)
	 */
	@Field(29) 
	public AVFrame repeat_pict(int repeat_pict) {
		this.io.setIntField(this, 29, repeat_pict);
		return this;
	}
	/** The content of the picture is interlaced. */
	@Field(30) 
	public int interlaced_frame() {
		return this.io.getIntField(this, 30);
	}
	/** The content of the picture is interlaced. */
	@Field(30) 
	public AVFrame interlaced_frame(int interlaced_frame) {
		this.io.setIntField(this, 30, interlaced_frame);
		return this;
	}
	/** If the content is interlaced, is top field displayed first. */
	@Field(31) 
	public int top_field_first() {
		return this.io.getIntField(this, 31);
	}
	/** If the content is interlaced, is top field displayed first. */
	@Field(31) 
	public AVFrame top_field_first(int top_field_first) {
		this.io.setIntField(this, 31, top_field_first);
		return this;
	}
	/** Tell user application that palette has changed from previous frame. */
	@Field(32) 
	public int palette_has_changed() {
		return this.io.getIntField(this, 32);
	}
	/** Tell user application that palette has changed from previous frame. */
	@Field(32) 
	public AVFrame palette_has_changed(int palette_has_changed) {
		this.io.setIntField(this, 32, palette_has_changed);
		return this;
	}
	@Field(33) 
	public int buffer_hints() {
		return this.io.getIntField(this, 33);
	}
	@Field(33) 
	public AVFrame buffer_hints(int buffer_hints) {
		this.io.setIntField(this, 33, buffer_hints);
		return this;
	}
	/**
	 * Pan scan.<br>
	 * C type : AVPanScan*
	 */
	@Field(34) 
	public Pointer<AVPanScan > pan_scan() {
		return this.io.getPointerField(this, 34);
	}
	/**
	 * Pan scan.<br>
	 * C type : AVPanScan*
	 */
	@Field(34) 
	public AVFrame pan_scan(Pointer<AVPanScan > pan_scan) {
		this.io.setPointerField(this, 34, pan_scan);
		return this;
	}
	/**
	 * reordered opaque 64bit (generally an integer or a double precision float<br>
	 * PTS but can be anything).<br>
	 * The user sets AVCodecContext.reordered_opaque to represent the input at<br>
	 * that time,<br>
	 * the decoder reorders values as needed and sets AVFrame.reordered_opaque<br>
	 * to exactly one of the values provided by the user through AVCodecContext.reordered_opaque<br>
	 * @deprecated in favor of pkt_pts
	 */
	@Alignment(4)
	@Field(35) 
	public long reordered_opaque() {
		return this.io.getLongField(this, 35);
	}
	/**
	 * reordered opaque 64bit (generally an integer or a double precision float<br>
	 * PTS but can be anything).<br>
	 * The user sets AVCodecContext.reordered_opaque to represent the input at<br>
	 * that time,<br>
	 * the decoder reorders values as needed and sets AVFrame.reordered_opaque<br>
	 * to exactly one of the values provided by the user through AVCodecContext.reordered_opaque<br>
	 * @deprecated in favor of pkt_pts
	 */
	@Alignment(4)
	@Field(35) 
	public AVFrame reordered_opaque(long reordered_opaque) {
		this.io.setLongField(this, 35, reordered_opaque);
		return this;
	}
	/**
	 * @deprecated this field is unused<br>
	 * C type : void*
	 */
	@Field(36) 
	public Pointer<? > hwaccel_picture_private() {
		return this.io.getPointerField(this, 36);
	}
	/**
	 * @deprecated this field is unused<br>
	 * C type : void*
	 */
	@Field(36) 
	public AVFrame hwaccel_picture_private(Pointer<? > hwaccel_picture_private) {
		this.io.setPointerField(this, 36, hwaccel_picture_private);
		return this;
	}
	/** C type : AVCodecContext* */
	@Field(37) 
	public Pointer<AVCodecContext > owner() {
		return this.io.getPointerField(this, 37);
	}
	/** C type : AVCodecContext* */
	@Field(37) 
	public AVFrame owner(Pointer<AVCodecContext > owner) {
		this.io.setPointerField(this, 37, owner);
		return this;
	}
	/** C type : void* */
	@Field(38) 
	public Pointer<? > thread_opaque() {
		return this.io.getPointerField(this, 38);
	}
	/** C type : void* */
	@Field(38) 
	public AVFrame thread_opaque(Pointer<? > thread_opaque) {
		this.io.setPointerField(this, 38, thread_opaque);
		return this;
	}
	/**
	 * log2 of the size of the block which a single vector in motion_val represents:<br>
	 * (4->16x16, 3->8x8, 2-> 4x4, 1-> 2x2)
	 */
	@Field(39) 
	public byte motion_subsample_log2() {
		return this.io.getByteField(this, 39);
	}
	/**
	 * log2 of the size of the block which a single vector in motion_val represents:<br>
	 * (4->16x16, 3->8x8, 2-> 4x4, 1-> 2x2)
	 */
	@Field(39) 
	public AVFrame motion_subsample_log2(byte motion_subsample_log2) {
		this.io.setByteField(this, 39, motion_subsample_log2);
		return this;
	}
	/** Sample rate of the audio data. */
	@Field(40) 
	public int sample_rate() {
		return this.io.getIntField(this, 40);
	}
	/** Sample rate of the audio data. */
	@Field(40) 
	public AVFrame sample_rate(int sample_rate) {
		this.io.setIntField(this, 40, sample_rate);
		return this;
	}
	/** Channel layout of the audio data. */
	@Field(41) 
	public long channel_layout() {
		return this.io.getLongField(this, 41);
	}
	/** Channel layout of the audio data. */
	@Field(41) 
	public AVFrame channel_layout(long channel_layout) {
		this.io.setLongField(this, 41, channel_layout);
		return this;
	}
	/**
	 * AVBuffer references backing the data for this frame. If all elements of<br>
	 * this array are NULL, then this frame is not reference counted. This array<br>
	 * must be filled contiguously -- if buf[i] is non-NULL then buf[j] must<br>
	 * also be non-NULL for all j < i.<br>
	 * * There may be at most one AVBuffer per data plane, so for video this array<br>
	 * always contains all the references. For planar audio with more than<br>
	 * AV_NUM_DATA_POINTERS channels, there may be more buffers than can fit in<br>
	 * this array. Then the extra AVBufferRef pointers are stored in the<br>
	 * extended_buf array.<br>
	 * C type : AVBufferRef*[8]
	 */
	@Array({8}) 
	@Field(42) 
	public Pointer<Pointer<AVBufferRef > > buf() {
		return this.io.getPointerField(this, 42);
	}
	/**
	 * For planar audio which requires more than AV_NUM_DATA_POINTERS<br>
	 * AVBufferRef pointers, this array will hold all the references which<br>
	 * cannot fit into AVFrame.buf.<br>
	 * * Note that this is different from AVFrame.extended_data, which always<br>
	 * contains all the pointers. This array only contains the extra pointers,<br>
	 * which cannot fit into AVFrame.buf.<br>
	 * * This array is always allocated using av_malloc() by whoever constructs<br>
	 * the frame. It is freed in av_frame_unref().<br>
	 * C type : AVBufferRef**
	 */
	@Field(43) 
	public Pointer<Pointer<AVBufferRef > > extended_buf() {
		return this.io.getPointerField(this, 43);
	}
	/**
	 * For planar audio which requires more than AV_NUM_DATA_POINTERS<br>
	 * AVBufferRef pointers, this array will hold all the references which<br>
	 * cannot fit into AVFrame.buf.<br>
	 * * Note that this is different from AVFrame.extended_data, which always<br>
	 * contains all the pointers. This array only contains the extra pointers,<br>
	 * which cannot fit into AVFrame.buf.<br>
	 * * This array is always allocated using av_malloc() by whoever constructs<br>
	 * the frame. It is freed in av_frame_unref().<br>
	 * C type : AVBufferRef**
	 */
	@Field(43) 
	public AVFrame extended_buf(Pointer<Pointer<AVBufferRef > > extended_buf) {
		this.io.setPointerField(this, 43, extended_buf);
		return this;
	}
	/** Number of elements in extended_buf. */
	@Field(44) 
	public int nb_extended_buf() {
		return this.io.getIntField(this, 44);
	}
	/** Number of elements in extended_buf. */
	@Field(44) 
	public AVFrame nb_extended_buf(int nb_extended_buf) {
		this.io.setIntField(this, 44, nb_extended_buf);
		return this;
	}
	/** C type : AVFrameSideData** */
	@Field(45) 
	public Pointer<Pointer<AVFrameSideData > > side_data() {
		return this.io.getPointerField(this, 45);
	}
	/** C type : AVFrameSideData** */
	@Field(45) 
	public AVFrame side_data(Pointer<Pointer<AVFrameSideData > > side_data) {
		this.io.setPointerField(this, 45, side_data);
		return this;
	}
	@Field(46) 
	public int nb_side_data() {
		return this.io.getIntField(this, 46);
	}
	@Field(46) 
	public AVFrame nb_side_data(int nb_side_data) {
		this.io.setIntField(this, 46, nb_side_data);
		return this;
	}
	/** Frame flags, a combination of @ref lavu_frame_flags */
	@Field(47) 
	public int flags() {
		return this.io.getIntField(this, 47);
	}
	/** Frame flags, a combination of @ref lavu_frame_flags */
	@Field(47) 
	public AVFrame flags(int flags) {
		this.io.setIntField(this, 47, flags);
		return this;
	}
	/**
	 * MPEG vs JPEG YUV range.<br>
	 * It must be accessed using av_frame_get_color_range() and<br>
	 * av_frame_set_color_range().<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorRange
	 */
	@Field(48) 
	public IntValuedEnum<AVColorRange > color_range() {
		return this.io.getEnumField(this, 48);
	}
	/**
	 * MPEG vs JPEG YUV range.<br>
	 * It must be accessed using av_frame_get_color_range() and<br>
	 * av_frame_set_color_range().<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorRange
	 */
	@Field(48) 
	public AVFrame color_range(IntValuedEnum<AVColorRange > color_range) {
		this.io.setEnumField(this, 48, color_range);
		return this;
	}
	/** C type : AVColorPrimaries */
	@Field(49) 
	public IntValuedEnum<AVColorPrimaries > color_primaries() {
		return this.io.getEnumField(this, 49);
	}
	/** C type : AVColorPrimaries */
	@Field(49) 
	public AVFrame color_primaries(IntValuedEnum<AVColorPrimaries > color_primaries) {
		this.io.setEnumField(this, 49, color_primaries);
		return this;
	}
	/** C type : AVColorTransferCharacteristic */
	@Field(50) 
	public IntValuedEnum<AVColorTransferCharacteristic > color_trc() {
		return this.io.getEnumField(this, 50);
	}
	/** C type : AVColorTransferCharacteristic */
	@Field(50) 
	public AVFrame color_trc(IntValuedEnum<AVColorTransferCharacteristic > color_trc) {
		this.io.setEnumField(this, 50, color_trc);
		return this;
	}
	/**
	 * YUV colorspace type.<br>
	 * It must be accessed using av_frame_get_colorspace() and<br>
	 * av_frame_set_colorspace().<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorSpace
	 */
	@Field(51) 
	public IntValuedEnum<AVColorSpace > colorspace() {
		return this.io.getEnumField(this, 51);
	}
	/**
	 * YUV colorspace type.<br>
	 * It must be accessed using av_frame_get_colorspace() and<br>
	 * av_frame_set_colorspace().<br>
	 * - encoding: Set by user<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : AVColorSpace
	 */
	@Field(51) 
	public AVFrame colorspace(IntValuedEnum<AVColorSpace > colorspace) {
		this.io.setEnumField(this, 51, colorspace);
		return this;
	}
	/** C type : AVChromaLocation */
	@Field(52) 
	public IntValuedEnum<AVChromaLocation > chroma_location() {
		return this.io.getEnumField(this, 52);
	}
	/** C type : AVChromaLocation */
	@Field(52) 
	public AVFrame chroma_location(IntValuedEnum<AVChromaLocation > chroma_location) {
		this.io.setEnumField(this, 52, chroma_location);
		return this;
	}
	/**
	 * frame timestamp estimated using various heuristics, in stream time base<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_best_effort_timestamp(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: set by libavcodec, read by user.
	 */
	@Field(53) 
	public long best_effort_timestamp() {
		return this.io.getLongField(this, 53);
	}
	/**
	 * frame timestamp estimated using various heuristics, in stream time base<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_best_effort_timestamp(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: set by libavcodec, read by user.
	 */
	@Field(53) 
	public AVFrame best_effort_timestamp(long best_effort_timestamp) {
		this.io.setLongField(this, 53, best_effort_timestamp);
		return this;
	}
	/**
	 * reordered pos from the last AVPacket that has been input into the decoder<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_pkt_pos(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	@Field(54) 
	public long pkt_pos() {
		return this.io.getLongField(this, 54);
	}
	/**
	 * reordered pos from the last AVPacket that has been input into the decoder<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_pkt_pos(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	@Field(54) 
	public AVFrame pkt_pos(long pkt_pos) {
		this.io.setLongField(this, 54, pkt_pos);
		return this;
	}
	/**
	 * duration of the corresponding packet, expressed in<br>
	 * AVStream->time_base units, 0 if unknown.<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_pkt_duration(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	@Field(55) 
	public long pkt_duration() {
		return this.io.getLongField(this, 55);
	}
	/**
	 * duration of the corresponding packet, expressed in<br>
	 * AVStream->time_base units, 0 if unknown.<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_pkt_duration(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	@Field(55) 
	public AVFrame pkt_duration(long pkt_duration) {
		this.io.setLongField(this, 55, pkt_duration);
		return this;
	}
	/**
	 * metadata.<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_metadata(frame)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : AVDictionary*
	 */
	@Field(56) 
	public Pointer<AVDictionary > metadata() {
		return this.io.getPointerField(this, 56);
	}
	/**
	 * metadata.<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_metadata(frame)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : AVDictionary*
	 */
	@Field(56) 
	public AVFrame metadata(Pointer<AVDictionary > metadata) {
		this.io.setPointerField(this, 56, metadata);
		return this;
	}
	/**
	 * decode error flags of the frame, set to a combination of<br>
	 * FF_DECODE_ERROR_xxx flags if the decoder produced a frame, but there<br>
	 * were errors during the decoding.<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_decode_error_flags(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: set by libavcodec, read by user.
	 */
	@Field(57) 
	public int decode_error_flags() {
		return this.io.getIntField(this, 57);
	}
	/**
	 * decode error flags of the frame, set to a combination of<br>
	 * FF_DECODE_ERROR_xxx flags if the decoder produced a frame, but there<br>
	 * were errors during the decoding.<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_decode_error_flags(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: set by libavcodec, read by user.
	 */
	@Field(57) 
	public AVFrame decode_error_flags(int decode_error_flags) {
		this.io.setIntField(this, 57, decode_error_flags);
		return this;
	}
	/**
	 * number of audio channels, only used for audio.<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_channels(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	@Field(58) 
	public int channels() {
		return this.io.getIntField(this, 58);
	}
	/**
	 * number of audio channels, only used for audio.<br>
	 * Code outside libavcodec should access this field using:<br>
	 * av_frame_get_channels(frame)<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	@Field(58) 
	public AVFrame channels(int channels) {
		this.io.setIntField(this, 58, channels);
		return this;
	}
	/**
	 * size of the corresponding packet containing the compressed<br>
	 * frame. It must be accessed using av_frame_get_pkt_size() and<br>
	 * av_frame_set_pkt_size().<br>
	 * It is set to a negative value if unknown.<br>
	 * - encoding: unused<br>
	 * - decoding: set by libavcodec, read by user.
	 */
	@Field(59) 
	public int pkt_size() {
		return this.io.getIntField(this, 59);
	}
	/**
	 * size of the corresponding packet containing the compressed<br>
	 * frame. It must be accessed using av_frame_get_pkt_size() and<br>
	 * av_frame_set_pkt_size().<br>
	 * It is set to a negative value if unknown.<br>
	 * - encoding: unused<br>
	 * - decoding: set by libavcodec, read by user.
	 */
	@Field(59) 
	public AVFrame pkt_size(int pkt_size) {
		this.io.setIntField(this, 59, pkt_size);
		return this;
	}
	/**
	 * Not to be accessed directly from outside libavutil<br>
	 * C type : AVBufferRef*
	 */
	@Field(60) 
	public Pointer<AVBufferRef > qp_table_buf() {
		return this.io.getPointerField(this, 60);
	}
	/**
	 * Not to be accessed directly from outside libavutil<br>
	 * C type : AVBufferRef*
	 */
	@Field(60) 
	public AVFrame qp_table_buf(Pointer<AVBufferRef > qp_table_buf) {
		this.io.setPointerField(this, 60, qp_table_buf);
		return this;
	}
	@Struct(customizer=AlignmentCustomizer.class)
	public AVFrame() {
		super();
	}
	@Struct(customizer=AlignmentCustomizer.class)
	public AVFrame(Pointer pointer) {
		super(pointer);
	}
	
	public List<StructFieldDescription> getDescriptions() {
		return this.io.desc.getAggregatedFields();
	}
}
