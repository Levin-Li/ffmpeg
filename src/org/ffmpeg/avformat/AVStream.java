package org.ffmpeg.avformat;
import org.bridj.BridJ;
import org.bridj.IntValuedEnum;
import org.bridj.Pointer;
import org.bridj.StructObject;
import org.bridj.ann.Array;
import org.bridj.ann.Field;
import org.bridj.ann.Library;
import org.bridj.ann.Struct;
import org.ffmpeg.avcodec.AVCodecContext;
import org.ffmpeg.avcodec.AVCodecParserContext;
import org.ffmpeg.avcodec.AVPacket;
import org.ffmpeg.avcodec.AVPacketSideData;
import org.ffmpeg.avcodec.AvcodecLibrary.AVDiscard;
import org.ffmpeg.avformat.AvformatLibrary.AVStreamParseType;
import org.ffmpeg.avutil.AVDictionary;
import org.ffmpeg.avutil.AVRational;
import org.ffmpeg.util.AlignmentCustomizer;
/**
 * <i>native declaration : libavformat/avformat.h:605</i><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> or <a href="http://bridj.googlecode.com/">BridJ</a> .
 */
@Library("avformat") 
public class AVStream extends StructObject {
	static {
		BridJ.register();
	}
	/** < stream index in AVFormatContext */
	@Field(0) 
	public int index() {
		return this.io.getIntField(this, 0);
	}
	/** < stream index in AVFormatContext */
	@Field(0) 
	public AVStream index(int index) {
		this.io.setIntField(this, 0, index);
		return this;
	}
	/**
	 * Format-specific stream ID.<br>
	 * decoding: set by libavformat<br>
	 * encoding: set by the user, replaced by libavformat if left unset
	 */
	@Field(1) 
	public int id() {
		return this.io.getIntField(this, 1);
	}
	/**
	 * Format-specific stream ID.<br>
	 * decoding: set by libavformat<br>
	 * encoding: set by the user, replaced by libavformat if left unset
	 */
	@Field(1) 
	public AVStream id(int id) {
		this.io.setIntField(this, 1, id);
		return this;
	}
	/**
	 * Codec context associated with this stream. Allocated and freed by<br>
	 * libavformat.<br>
	 * * - decoding: The demuxer exports codec information stored in the headers<br>
	 *             here.<br>
	 * - encoding: The user sets codec information, the muxer writes it to the<br>
	 *             output. Mandatory fields as specified in AVCodecContext<br>
	 *             documentation must be set even if this AVCodecContext is<br>
	 *             not actually used for encoding.<br>
	 * C type : AVCodecContext*
	 */
	@Field(2) 
	public Pointer<AVCodecContext > codec() {
		return this.io.getPointerField(this, 2);
	}
	/**
	 * Codec context associated with this stream. Allocated and freed by<br>
	 * libavformat.<br>
	 * * - decoding: The demuxer exports codec information stored in the headers<br>
	 *             here.<br>
	 * - encoding: The user sets codec information, the muxer writes it to the<br>
	 *             output. Mandatory fields as specified in AVCodecContext<br>
	 *             documentation must be set even if this AVCodecContext is<br>
	 *             not actually used for encoding.<br>
	 * C type : AVCodecContext*
	 */
	@Field(2) 
	public AVStream codec(Pointer<AVCodecContext > codec) {
		this.io.setPointerField(this, 2, codec);
		return this;
	}
	/** C type : void* */
	@Field(3) 
	public Pointer<? > priv_data() {
		return this.io.getPointerField(this, 3);
	}
	/** C type : void* */
	@Field(3) 
	public AVStream priv_data(Pointer<? > priv_data) {
		this.io.setPointerField(this, 3, priv_data);
		return this;
	}
	/**
	 * @deprecated this field is unused<br>
	 * C type : AVFrac
	 */
	@Field(4) 
	public AVFrac pts() {
		return this.io.getNativeObjectField(this, 4);
	}
	/**
	 * @deprecated this field is unused<br>
	 * C type : AVFrac
	 */
	@Field(4) 
	public AVStream pts(AVFrac pts) {
		this.io.setNativeObjectField(this, 4, pts);
		return this;
	}
	/**
	 * This is the fundamental unit of time (in seconds) in terms<br>
	 * of which frame timestamps are represented.<br>
	 * * decoding: set by libavformat<br>
	 * encoding: May be set by the caller before avformat_write_header() to<br>
	 *           provide a hint to the muxer about the desired timebase. In<br>
	 *           avformat_write_header(), the muxer will overwrite this field<br>
	 *           with the timebase that will actually be used for the timestamps<br>
	 *           written into the file (which may or may not be related to the<br>
	 *           user-provided one, depending on the format).<br>
	 * C type : AVRational
	 */
	@Field(5) 
	public AVRational time_base() {
		return this.io.getNativeObjectField(this, 5);
	}
	/**
	 * This is the fundamental unit of time (in seconds) in terms<br>
	 * of which frame timestamps are represented.<br>
	 * * decoding: set by libavformat<br>
	 * encoding: May be set by the caller before avformat_write_header() to<br>
	 *           provide a hint to the muxer about the desired timebase. In<br>
	 *           avformat_write_header(), the muxer will overwrite this field<br>
	 *           with the timebase that will actually be used for the timestamps<br>
	 *           written into the file (which may or may not be related to the<br>
	 *           user-provided one, depending on the format).<br>
	 * C type : AVRational
	 */
	@Field(5) 
	public AVStream time_base(AVRational time_base) {
		this.io.setNativeObjectField(this, 5, time_base);
		return this;
	}
	/**
	 * Decoding: pts of the first frame of the stream in presentation order, in stream time base.<br>
	 * Only set this if you are absolutely 100% sure that the value you set<br>
	 * it to really is the pts of the first frame.<br>
	 * This may be undefined (AV_NOPTS_VALUE).<br>
	 * @note The ASF header does NOT contain a correct start_time the ASF<br>
	 * demuxer must NOT set this.
	 */
	@Field(6) 
	public long start_time() {
		return this.io.getLongField(this, 6);
	}
	/**
	 * Decoding: pts of the first frame of the stream in presentation order, in stream time base.<br>
	 * Only set this if you are absolutely 100% sure that the value you set<br>
	 * it to really is the pts of the first frame.<br>
	 * This may be undefined (AV_NOPTS_VALUE).<br>
	 * @note The ASF header does NOT contain a correct start_time the ASF<br>
	 * demuxer must NOT set this.
	 */
	@Field(6) 
	public AVStream start_time(long start_time) {
		this.io.setLongField(this, 6, start_time);
		return this;
	}
	/**
	 * Decoding: duration of the stream, in stream time base.<br>
	 * If a source file does not specify a duration, but does specify<br>
	 * a bitrate, this value will be estimated from bitrate and file size.
	 */
	@Field(7) 
	public long duration() {
		return this.io.getLongField(this, 7);
	}
	/**
	 * Decoding: duration of the stream, in stream time base.<br>
	 * If a source file does not specify a duration, but does specify<br>
	 * a bitrate, this value will be estimated from bitrate and file size.
	 */
	@Field(7) 
	public AVStream duration(long duration) {
		this.io.setLongField(this, 7, duration);
		return this;
	}
	/** < number of frames in this stream if known or 0 */
	@Field(8) 
	public long nb_frames() {
		return this.io.getLongField(this, 8);
	}
	/** < number of frames in this stream if known or 0 */
	@Field(8) 
	public AVStream nb_frames(long nb_frames) {
		this.io.setLongField(this, 8, nb_frames);
		return this;
	}
	/** < AV_DISPOSITION_* bit field */
	@Field(9) 
	public int disposition() {
		return this.io.getIntField(this, 9);
	}
	/** < AV_DISPOSITION_* bit field */
	@Field(9) 
	public AVStream disposition(int disposition) {
		this.io.setIntField(this, 9, disposition);
		return this;
	}
	/**
	 * < Selects which packets can be discarded at will and do not need to be demuxed.<br>
	 * C type : AVDiscard
	 */
	@Field(10) 
	public IntValuedEnum<AVDiscard > discard() {
		return this.io.getEnumField(this, 10);
	}
	/**
	 * < Selects which packets can be discarded at will and do not need to be demuxed.<br>
	 * C type : AVDiscard
	 */
	@Field(10) 
	public AVStream discard(IntValuedEnum<AVDiscard > discard) {
		this.io.setEnumField(this, 10, discard);
		return this;
	}
	/**
	 * sample aspect ratio (0 if unknown)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavformat.<br>
	 * C type : AVRational
	 */
	@Field(11) 
	public AVRational sample_aspect_ratio() {
		return this.io.getNativeObjectField(this, 11);
	}
	/**
	 * sample aspect ratio (0 if unknown)<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavformat.<br>
	 * C type : AVRational
	 */
	@Field(11) 
	public AVStream sample_aspect_ratio(AVRational sample_aspect_ratio) {
		this.io.setNativeObjectField(this, 11, sample_aspect_ratio);
		return this;
	}
	/** C type : AVDictionary* */
	@Field(12) 
	public Pointer<AVDictionary > metadata() {
		return this.io.getPointerField(this, 12);
	}
	/** C type : AVDictionary* */
	@Field(12) 
	public AVStream metadata(Pointer<AVDictionary > metadata) {
		this.io.setPointerField(this, 12, metadata);
		return this;
	}
	/**
	 * Average framerate<br>
	 * * - demuxing: May be set by libavformat when creating the stream or in<br>
	 *             avformat_find_stream_info().<br>
	 * - muxing: May be set by the caller before avformat_write_header().<br>
	 * C type : AVRational
	 */
	@Field(13) 
	public AVRational avg_frame_rate() {
		return this.io.getNativeObjectField(this, 13);
	}
	/**
	 * Average framerate<br>
	 * * - demuxing: May be set by libavformat when creating the stream or in<br>
	 *             avformat_find_stream_info().<br>
	 * - muxing: May be set by the caller before avformat_write_header().<br>
	 * C type : AVRational
	 */
	@Field(13) 
	public AVStream avg_frame_rate(AVRational avg_frame_rate) {
		this.io.setNativeObjectField(this, 13, avg_frame_rate);
		return this;
	}
	/**
	 * For streams with AV_DISPOSITION_ATTACHED_PIC disposition, this packet<br>
	 * will contain the attached picture.<br>
	 * * decoding: set by libavformat, must not be modified by the caller.<br>
	 * encoding: unused<br>
	 * C type : AVPacket
	 */
	@Field(14) 
	public AVPacket attached_pic() {
		return this.io.getNativeObjectField(this, 14);
	}
	/**
	 * For streams with AV_DISPOSITION_ATTACHED_PIC disposition, this packet<br>
	 * will contain the attached picture.<br>
	 * * decoding: set by libavformat, must not be modified by the caller.<br>
	 * encoding: unused<br>
	 * C type : AVPacket
	 */
	@Field(14) 
	public AVStream attached_pic(AVPacket attached_pic) {
		this.io.setNativeObjectField(this, 14, attached_pic);
		return this;
	}
	/**
	 * An array of side data that applies to the whole stream (i.e. the<br>
	 * container does not allow it to change between packets).<br>
	 * * There may be no overlap between the side data in this array and side data<br>
	 * in the packets. I.e. a given side data is either exported by the muxer<br>
	 * (demuxing) / set by the caller (muxing) in this array, then it never<br>
	 * appears in the packets, or the side data is exported / sent through<br>
	 * the packets (always in the first packet where the value becomes known or<br>
	 * changes), then it does not appear in this array.<br>
	 * * - demuxing: Set by libavformat when the stream is created.<br>
	 * - muxing: May be set by the caller before avformat_write_header().<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * * @see av_format_inject_global_side_data()<br>
	 * C type : AVPacketSideData*
	 */
	@Field(15) 
	public Pointer<AVPacketSideData > side_data() {
		return this.io.getPointerField(this, 15);
	}
	/**
	 * An array of side data that applies to the whole stream (i.e. the<br>
	 * container does not allow it to change between packets).<br>
	 * * There may be no overlap between the side data in this array and side data<br>
	 * in the packets. I.e. a given side data is either exported by the muxer<br>
	 * (demuxing) / set by the caller (muxing) in this array, then it never<br>
	 * appears in the packets, or the side data is exported / sent through<br>
	 * the packets (always in the first packet where the value becomes known or<br>
	 * changes), then it does not appear in this array.<br>
	 * * - demuxing: Set by libavformat when the stream is created.<br>
	 * - muxing: May be set by the caller before avformat_write_header().<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * * @see av_format_inject_global_side_data()<br>
	 * C type : AVPacketSideData*
	 */
	@Field(15) 
	public AVStream side_data(Pointer<AVPacketSideData > side_data) {
		this.io.setPointerField(this, 15, side_data);
		return this;
	}
	/** The number of elements in the AVStream.side_data array. */
	@Field(16) 
	public int nb_side_data() {
		return this.io.getIntField(this, 16);
	}
	/** The number of elements in the AVStream.side_data array. */
	@Field(16) 
	public AVStream nb_side_data(int nb_side_data) {
		this.io.setIntField(this, 16, nb_side_data);
		return this;
	}
	/**
	 * Flags for the user to detect events happening on the stream. Flags must<br>
	 * be cleared by the user once the event has been handled.<br>
	 * A combination of AVSTREAM_EVENT_FLAG_*.
	 */
	@Field(17) 
	public int event_flags() {
		return this.io.getIntField(this, 17);
	}
	/**
	 * Flags for the user to detect events happening on the stream. Flags must<br>
	 * be cleared by the user once the event has been handled.<br>
	 * A combination of AVSTREAM_EVENT_FLAG_*.
	 */
	@Field(17) 
	public AVStream event_flags(int event_flags) {
		this.io.setIntField(this, 17, event_flags);
		return this;
	}
	/** C type : info_struct* */
	@Field(18) 
	public Pointer<AVStream.info_struct > info() {
		return this.io.getPointerField(this, 18);
	}
	/** C type : info_struct* */
	@Field(18) 
	public AVStream info(Pointer<AVStream.info_struct > info) {
		this.io.setPointerField(this, 18, info);
		return this;
	}
	/** < number of bits in pts (used for wrapping control) */
	@Field(19) 
	public int pts_wrap_bits() {
		return this.io.getIntField(this, 19);
	}
	/** < number of bits in pts (used for wrapping control) */
	@Field(19) 
	public AVStream pts_wrap_bits(int pts_wrap_bits) {
		this.io.setIntField(this, 19, pts_wrap_bits);
		return this;
	}
	/**
	 * Timestamp corresponding to the last dts sync point.<br>
	 * * Initialized when AVCodecParserContext.dts_sync_point >= 0 and<br>
	 * a DTS is received from the underlying container. Otherwise set to<br>
	 * AV_NOPTS_VALUE by default.
	 */
	@Field(20) 
	public long first_dts() {
		return this.io.getLongField(this, 20);
	}
	/**
	 * Timestamp corresponding to the last dts sync point.<br>
	 * * Initialized when AVCodecParserContext.dts_sync_point >= 0 and<br>
	 * a DTS is received from the underlying container. Otherwise set to<br>
	 * AV_NOPTS_VALUE by default.
	 */
	@Field(20) 
	public AVStream first_dts(long first_dts) {
		this.io.setLongField(this, 20, first_dts);
		return this;
	}
	@Field(21) 
	public long cur_dts() {
		return this.io.getLongField(this, 21);
	}
	@Field(21) 
	public AVStream cur_dts(long cur_dts) {
		this.io.setLongField(this, 21, cur_dts);
		return this;
	}
	@Field(22) 
	public long last_IP_pts() {
		return this.io.getLongField(this, 22);
	}
	@Field(22) 
	public AVStream last_IP_pts(long last_IP_pts) {
		this.io.setLongField(this, 22, last_IP_pts);
		return this;
	}
	@Field(23) 
	public int last_IP_duration() {
		return this.io.getIntField(this, 23);
	}
	@Field(23) 
	public AVStream last_IP_duration(int last_IP_duration) {
		this.io.setIntField(this, 23, last_IP_duration);
		return this;
	}
	/** Number of packets to buffer for codec probing */
	@Field(24) 
	public int probe_packets() {
		return this.io.getIntField(this, 24);
	}
	/** Number of packets to buffer for codec probing */
	@Field(24) 
	public AVStream probe_packets(int probe_packets) {
		this.io.setIntField(this, 24, probe_packets);
		return this;
	}
	/** Number of frames that have been demuxed during av_find_stream_info() */
	@Field(25) 
	public int codec_info_nb_frames() {
		return this.io.getIntField(this, 25);
	}
	/** Number of frames that have been demuxed during av_find_stream_info() */
	@Field(25) 
	public AVStream codec_info_nb_frames(int codec_info_nb_frames) {
		this.io.setIntField(this, 25, codec_info_nb_frames);
		return this;
	}
	/**
	 * av_read_frame() support<br>
	 * C type : AVStreamParseType
	 */
	@Field(26) 
	public IntValuedEnum<AVStreamParseType > need_parsing() {
		return this.io.getEnumField(this, 26);
	}
	/**
	 * av_read_frame() support<br>
	 * C type : AVStreamParseType
	 */
	@Field(26) 
	public AVStream need_parsing(IntValuedEnum<AVStreamParseType > need_parsing) {
		this.io.setEnumField(this, 26, need_parsing);
		return this;
	}
	/** C type : AVCodecParserContext* */
	@Field(27) 
	public Pointer<AVCodecParserContext > parser() {
		return this.io.getPointerField(this, 27);
	}
	/** C type : AVCodecParserContext* */
	@Field(27) 
	public AVStream parser(Pointer<AVCodecParserContext > parser) {
		this.io.setPointerField(this, 27, parser);
		return this;
	}
	/**
	 * last packet in packet_buffer for this stream when muxing.<br>
	 * C type : AVPacketList*
	 */
	@Field(28) 
	public Pointer<AVPacketList > last_in_packet_buffer() {
		return this.io.getPointerField(this, 28);
	}
	/**
	 * last packet in packet_buffer for this stream when muxing.<br>
	 * C type : AVPacketList*
	 */
	@Field(28) 
	public AVStream last_in_packet_buffer(Pointer<AVPacketList > last_in_packet_buffer) {
		this.io.setPointerField(this, 28, last_in_packet_buffer);
		return this;
	}
	/** C type : AVProbeData */
	@Field(29) 
	public AVProbeData probe_data() {
		return this.io.getNativeObjectField(this, 29);
	}
	/** C type : AVProbeData */
	@Field(29) 
	public AVStream probe_data(AVProbeData probe_data) {
		this.io.setNativeObjectField(this, 29, probe_data);
		return this;
	}
	/** C type : int64_t[16 + 1] */
	@Array({16 + 1}) 
	@Field(30) 
	public Pointer<Long > pts_buffer() {
		return this.io.getPointerField(this, 30);
	}
	/**
	 * < Only used if the format does not<br>
	 * support seeking natively.<br>
	 * C type : AVIndexEntry*
	 */
	@Field(31) 
	public Pointer<AVIndexEntry > index_entries() {
		return this.io.getPointerField(this, 31);
	}
	/**
	 * < Only used if the format does not<br>
	 * support seeking natively.<br>
	 * C type : AVIndexEntry*
	 */
	@Field(31) 
	public AVStream index_entries(Pointer<AVIndexEntry > index_entries) {
		this.io.setPointerField(this, 31, index_entries);
		return this;
	}
	@Field(32) 
	public int nb_index_entries() {
		return this.io.getIntField(this, 32);
	}
	@Field(32) 
	public AVStream nb_index_entries(int nb_index_entries) {
		this.io.setIntField(this, 32, nb_index_entries);
		return this;
	}
	@Field(33) 
	public int index_entries_allocated_size() {
		return this.io.getIntField(this, 33);
	}
	@Field(33) 
	public AVStream index_entries_allocated_size(int index_entries_allocated_size) {
		this.io.setIntField(this, 33, index_entries_allocated_size);
		return this;
	}
	/**
	 * Real base framerate of the stream.<br>
	 * This is the lowest framerate with which all timestamps can be<br>
	 * represented accurately (it is the least common multiple of all<br>
	 * framerates in the stream). Note, this value is just a guess!<br>
	 * For example, if the time base is 1/90000 and all frames have either<br>
	 * approximately 3600 or 1800 timer ticks, then r_frame_rate will be 50/1.<br>
	 * * Code outside avformat should access this field using:<br>
	 * av_stream_get/set_r_frame_rate(stream)<br>
	 * C type : AVRational
	 */
	@Field(34) 
	public AVRational r_frame_rate() {
		return this.io.getNativeObjectField(this, 34);
	}
	/**
	 * Real base framerate of the stream.<br>
	 * This is the lowest framerate with which all timestamps can be<br>
	 * represented accurately (it is the least common multiple of all<br>
	 * framerates in the stream). Note, this value is just a guess!<br>
	 * For example, if the time base is 1/90000 and all frames have either<br>
	 * approximately 3600 or 1800 timer ticks, then r_frame_rate will be 50/1.<br>
	 * * Code outside avformat should access this field using:<br>
	 * av_stream_get/set_r_frame_rate(stream)<br>
	 * C type : AVRational
	 */
	@Field(34) 
	public AVStream r_frame_rate(AVRational r_frame_rate) {
		this.io.setNativeObjectField(this, 34, r_frame_rate);
		return this;
	}
	/**
	 * Stream Identifier<br>
	 * This is the MPEG-TS stream identifier +1<br>
	 * 0 means unknown
	 */
	@Field(35) 
	public int stream_identifier() {
		return this.io.getIntField(this, 35);
	}
	/**
	 * Stream Identifier<br>
	 * This is the MPEG-TS stream identifier +1<br>
	 * 0 means unknown
	 */
	@Field(35) 
	public AVStream stream_identifier(int stream_identifier) {
		this.io.setIntField(this, 35, stream_identifier);
		return this;
	}
	@Field(36) 
	public long interleaver_chunk_size() {
		return this.io.getLongField(this, 36);
	}
	@Field(36) 
	public AVStream interleaver_chunk_size(long interleaver_chunk_size) {
		this.io.setLongField(this, 36, interleaver_chunk_size);
		return this;
	}
	@Field(37) 
	public long interleaver_chunk_duration() {
		return this.io.getLongField(this, 37);
	}
	@Field(37) 
	public AVStream interleaver_chunk_duration(long interleaver_chunk_duration) {
		this.io.setLongField(this, 37, interleaver_chunk_duration);
		return this;
	}
	/**
	 * stream probing state<br>
	 * -1   -> probing finished<br>
	 *  0   -> no probing requested<br>
	 * rest -> perform probing with request_probe being the minimum score to accept.<br>
	 * NOT PART OF PUBLIC API
	 */
	@Field(38) 
	public int request_probe() {
		return this.io.getIntField(this, 38);
	}
	/**
	 * stream probing state<br>
	 * -1   -> probing finished<br>
	 *  0   -> no probing requested<br>
	 * rest -> perform probing with request_probe being the minimum score to accept.<br>
	 * NOT PART OF PUBLIC API
	 */
	@Field(38) 
	public AVStream request_probe(int request_probe) {
		this.io.setIntField(this, 38, request_probe);
		return this;
	}
	/**
	 * Indicates that everything up to the next keyframe<br>
	 * should be discarded.
	 */
	@Field(39) 
	public int skip_to_keyframe() {
		return this.io.getIntField(this, 39);
	}
	/**
	 * Indicates that everything up to the next keyframe<br>
	 * should be discarded.
	 */
	@Field(39) 
	public AVStream skip_to_keyframe(int skip_to_keyframe) {
		this.io.setIntField(this, 39, skip_to_keyframe);
		return this;
	}
	/** Number of samples to skip at the start of the frame decoded from the next packet. */
	@Field(40) 
	public int skip_samples() {
		return this.io.getIntField(this, 40);
	}
	/** Number of samples to skip at the start of the frame decoded from the next packet. */
	@Field(40) 
	public AVStream skip_samples(int skip_samples) {
		this.io.setIntField(this, 40, skip_samples);
		return this;
	}
	/**
	 * If not 0, the number of samples that should be skipped from the start of<br>
	 * the stream (the samples are removed from packets with pts==0, which also<br>
	 * assumes negative timestamps do not happen).<br>
	 * Intended for use with formats such as mp3 with ad-hoc gapless audio<br>
	 * support.
	 */
	@Field(41) 
	public long start_skip_samples() {
		return this.io.getLongField(this, 41);
	}
	/**
	 * If not 0, the number of samples that should be skipped from the start of<br>
	 * the stream (the samples are removed from packets with pts==0, which also<br>
	 * assumes negative timestamps do not happen).<br>
	 * Intended for use with formats such as mp3 with ad-hoc gapless audio<br>
	 * support.
	 */
	@Field(41) 
	public AVStream start_skip_samples(long start_skip_samples) {
		this.io.setLongField(this, 41, start_skip_samples);
		return this;
	}
	/**
	 * If not 0, the first audio sample that should be discarded from the stream.<br>
	 * This is broken by design (needs global sample count), but can't be<br>
	 * avoided for broken by design formats such as mp3 with ad-hoc gapless<br>
	 * audio support.
	 */
	@Field(42) 
	public long first_discard_sample() {
		return this.io.getLongField(this, 42);
	}
	/**
	 * If not 0, the first audio sample that should be discarded from the stream.<br>
	 * This is broken by design (needs global sample count), but can't be<br>
	 * avoided for broken by design formats such as mp3 with ad-hoc gapless<br>
	 * audio support.
	 */
	@Field(42) 
	public AVStream first_discard_sample(long first_discard_sample) {
		this.io.setLongField(this, 42, first_discard_sample);
		return this;
	}
	/**
	 * The sample after last sample that is intended to be discarded after<br>
	 * first_discard_sample. Works on frame boundaries only. Used to prevent<br>
	 * early EOF if the gapless info is broken (considered concatenated mp3s).
	 */
	@Field(43) 
	public long last_discard_sample() {
		return this.io.getLongField(this, 43);
	}
	/**
	 * The sample after last sample that is intended to be discarded after<br>
	 * first_discard_sample. Works on frame boundaries only. Used to prevent<br>
	 * early EOF if the gapless info is broken (considered concatenated mp3s).
	 */
	@Field(43) 
	public AVStream last_discard_sample(long last_discard_sample) {
		this.io.setLongField(this, 43, last_discard_sample);
		return this;
	}
	/**
	 * Number of internally decoded frames, used internally in libavformat, do not access<br>
	 * its lifetime differs from info which is why it is not in that structure.
	 */
	@Field(44) 
	public int nb_decoded_frames() {
		return this.io.getIntField(this, 44);
	}
	/**
	 * Number of internally decoded frames, used internally in libavformat, do not access<br>
	 * its lifetime differs from info which is why it is not in that structure.
	 */
	@Field(44) 
	public AVStream nb_decoded_frames(int nb_decoded_frames) {
		this.io.setIntField(this, 44, nb_decoded_frames);
		return this;
	}
	/**
	 * Timestamp offset added to timestamps before muxing<br>
	 * NOT PART OF PUBLIC API
	 */
	@Field(45) 
	public long mux_ts_offset() {
		return this.io.getLongField(this, 45);
	}
	/**
	 * Timestamp offset added to timestamps before muxing<br>
	 * NOT PART OF PUBLIC API
	 */
	@Field(45) 
	public AVStream mux_ts_offset(long mux_ts_offset) {
		this.io.setLongField(this, 45, mux_ts_offset);
		return this;
	}
	/** Internal data to check for wrapping of the time stamp */
	@Field(46) 
	public long pts_wrap_reference() {
		return this.io.getLongField(this, 46);
	}
	/** Internal data to check for wrapping of the time stamp */
	@Field(46) 
	public AVStream pts_wrap_reference(long pts_wrap_reference) {
		this.io.setLongField(this, 46, pts_wrap_reference);
		return this;
	}
	/**
	 * Options for behavior, when a wrap is detected.<br>
	 * * Defined by AV_PTS_WRAP_ values.<br>
	 * * If correction is enabled, there are two possibilities:<br>
	 * If the first time stamp is near the wrap point, the wrap offset<br>
	 * will be subtracted, which will create negative time stamps.<br>
	 * Otherwise the offset will be added.
	 */
	@Field(47) 
	public int pts_wrap_behavior() {
		return this.io.getIntField(this, 47);
	}
	/**
	 * Options for behavior, when a wrap is detected.<br>
	 * * Defined by AV_PTS_WRAP_ values.<br>
	 * * If correction is enabled, there are two possibilities:<br>
	 * If the first time stamp is near the wrap point, the wrap offset<br>
	 * will be subtracted, which will create negative time stamps.<br>
	 * Otherwise the offset will be added.
	 */
	@Field(47) 
	public AVStream pts_wrap_behavior(int pts_wrap_behavior) {
		this.io.setIntField(this, 47, pts_wrap_behavior);
		return this;
	}
	/** Internal data to prevent doing update_initial_durations() twice */
	@Field(48) 
	public int update_initial_durations_done() {
		return this.io.getIntField(this, 48);
	}
	/** Internal data to prevent doing update_initial_durations() twice */
	@Field(48) 
	public AVStream update_initial_durations_done(int update_initial_durations_done) {
		this.io.setIntField(this, 48, update_initial_durations_done);
		return this;
	}
	/**
	 * Internal data to generate dts from pts<br>
	 * C type : int64_t[16 + 1]
	 */
	@Array({16 + 1}) 
	@Field(49) 
	public Pointer<Long > pts_reorder_error() {
		return this.io.getPointerField(this, 49);
	}
	/** C type : uint8_t[16 + 1] */
	@Array({16 + 1}) 
	@Field(50) 
	public Pointer<Byte > pts_reorder_error_count() {
		return this.io.getPointerField(this, 50);
	}
	/** Internal data to analyze DTS and detect faulty mpeg streams */
	@Field(51) 
	public long last_dts_for_order_check() {
		return this.io.getLongField(this, 51);
	}
	/** Internal data to analyze DTS and detect faulty mpeg streams */
	@Field(51) 
	public AVStream last_dts_for_order_check(long last_dts_for_order_check) {
		this.io.setLongField(this, 51, last_dts_for_order_check);
		return this;
	}
	@Field(52) 
	public byte dts_ordered() {
		return this.io.getByteField(this, 52);
	}
	@Field(52) 
	public AVStream dts_ordered(byte dts_ordered) {
		this.io.setByteField(this, 52, dts_ordered);
		return this;
	}
	@Field(53) 
	public byte dts_misordered() {
		return this.io.getByteField(this, 53);
	}
	@Field(53) 
	public AVStream dts_misordered(byte dts_misordered) {
		this.io.setByteField(this, 53, dts_misordered);
		return this;
	}
	/** Internal data to inject global side data */
	@Field(54) 
	public int inject_global_side_data() {
		return this.io.getIntField(this, 54);
	}
	/** Internal data to inject global side data */
	@Field(54) 
	public AVStream inject_global_side_data(int inject_global_side_data) {
		this.io.setIntField(this, 54, inject_global_side_data);
		return this;
	}
	/**
	 * String containing paris of key and values describing recommended encoder configuration.<br>
	 * Paris are separated by ','.<br>
	 * Keys are separated from values by '='.<br>
	 * C type : char*
	 */
	@Field(55) 
	public Pointer<Byte > recommended_encoder_configuration() {
		return this.io.getPointerField(this, 55);
	}
	/**
	 * String containing paris of key and values describing recommended encoder configuration.<br>
	 * Paris are separated by ','.<br>
	 * Keys are separated from values by '='.<br>
	 * C type : char*
	 */
	@Field(55) 
	public AVStream recommended_encoder_configuration(Pointer<Byte > recommended_encoder_configuration) {
		this.io.setPointerField(this, 55, recommended_encoder_configuration);
		return this;
	}
	/**
	 * display aspect ratio (0 if unknown)<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavformat to calculate sample_aspect_ratio internally<br>
	 * C type : AVRational
	 */
	@Field(56) 
	public AVRational display_aspect_ratio() {
		return this.io.getNativeObjectField(this, 56);
	}
	/**
	 * display aspect ratio (0 if unknown)<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavformat to calculate sample_aspect_ratio internally<br>
	 * C type : AVRational
	 */
	@Field(56) 
	public AVStream display_aspect_ratio(AVRational display_aspect_ratio) {
		this.io.setNativeObjectField(this, 56, display_aspect_ratio);
		return this;
	}
	/** C type : FFFrac* */
	@Field(57) 
	public Pointer<FFFrac > priv_pts() {
		return this.io.getPointerField(this, 57);
	}
	/** C type : FFFrac* */
	@Field(57) 
	public AVStream priv_pts(Pointer<FFFrac > priv_pts) {
		this.io.setPointerField(this, 57, priv_pts);
		return this;
	}
	/**
	 * An opaque field for libavformat internal usage.<br>
	 * Must not be accessed in any way by callers.<br>
	 * C type : AVStreamInternal*
	 */
	@Field(58) 
	public Pointer<AVStreamInternal > internal() {
		return this.io.getPointerField(this, 58);
	}
	/**
	 * An opaque field for libavformat internal usage.<br>
	 * Must not be accessed in any way by callers.<br>
	 * C type : AVStreamInternal*
	 */
	@Field(58) 
	public AVStream internal(Pointer<AVStreamInternal > internal) {
		this.io.setPointerField(this, 58, internal);
		return this;
	}
	/** <i>native declaration : libavformat/avformat.h:602</i> */
	public static class info_struct extends StructObject {
		static {
			BridJ.register();
		}
		@Field(0) 
		public long last_dts() {
			return this.io.getLongField(this, 0);
		}
		@Field(0) 
		public info_struct last_dts(long last_dts) {
			this.io.setLongField(this, 0, last_dts);
			return this;
		}
		@Field(1) 
		public long duration_gcd() {
			return this.io.getLongField(this, 1);
		}
		@Field(1) 
		public info_struct duration_gcd(long duration_gcd) {
			this.io.setLongField(this, 1, duration_gcd);
			return this;
		}
		@Field(2) 
		public int duration_count() {
			return this.io.getIntField(this, 2);
		}
		@Field(2) 
		public info_struct duration_count(int duration_count) {
			this.io.setIntField(this, 2, duration_count);
			return this;
		}
		@Field(3) 
		public long rfps_duration_sum() {
			return this.io.getLongField(this, 3);
		}
		@Field(3) 
		public info_struct rfps_duration_sum(long rfps_duration_sum) {
			this.io.setLongField(this, 3, rfps_duration_sum);
			return this;
		}
		/** C type : double[2][(30 * 12 + 30 + 3 + 6)]* */
		@Field(4) 
		public Pointer<Pointer<Double > > duration_error() {
			return this.io.getPointerField(this, 4);
		}
		/** C type : double[2][(30 * 12 + 30 + 3 + 6)]* */
		@Field(4) 
		public info_struct duration_error(Pointer<Pointer<Double > > duration_error) {
			this.io.setPointerField(this, 4, duration_error);
			return this;
		}
		@Field(5) 
		public long codec_info_duration() {
			return this.io.getLongField(this, 5);
		}
		@Field(5) 
		public info_struct codec_info_duration(long codec_info_duration) {
			this.io.setLongField(this, 5, codec_info_duration);
			return this;
		}
		@Field(6) 
		public long codec_info_duration_fields() {
			return this.io.getLongField(this, 6);
		}
		@Field(6) 
		public info_struct codec_info_duration_fields(long codec_info_duration_fields) {
			this.io.setLongField(this, 6, codec_info_duration_fields);
			return this;
		}
		/**
		 * 0  -> decoder has not been searched for yet.<br>
		 * >0 -> decoder found<br>
		 * <0 -> decoder with codec_id == -found_decoder has not been found
		 */
		@Field(7) 
		public int found_decoder() {
			return this.io.getIntField(this, 7);
		}
		/**
		 * 0  -> decoder has not been searched for yet.<br>
		 * >0 -> decoder found<br>
		 * <0 -> decoder with codec_id == -found_decoder has not been found
		 */
		@Field(7) 
		public info_struct found_decoder(int found_decoder) {
			this.io.setIntField(this, 7, found_decoder);
			return this;
		}
		@Field(8) 
		public long last_duration() {
			return this.io.getLongField(this, 8);
		}
		@Field(8) 
		public info_struct last_duration(long last_duration) {
			this.io.setLongField(this, 8, last_duration);
			return this;
		}
		/** Those are used for average framerate estimation. */
		@Field(9) 
		public long fps_first_dts() {
			return this.io.getLongField(this, 9);
		}
		/** Those are used for average framerate estimation. */
		@Field(9) 
		public info_struct fps_first_dts(long fps_first_dts) {
			this.io.setLongField(this, 9, fps_first_dts);
			return this;
		}
		@Field(10) 
		public int fps_first_dts_idx() {
			return this.io.getIntField(this, 10);
		}
		@Field(10) 
		public info_struct fps_first_dts_idx(int fps_first_dts_idx) {
			this.io.setIntField(this, 10, fps_first_dts_idx);
			return this;
		}
		@Field(11) 
		public long fps_last_dts() {
			return this.io.getLongField(this, 11);
		}
		@Field(11) 
		public info_struct fps_last_dts(long fps_last_dts) {
			this.io.setLongField(this, 11, fps_last_dts);
			return this;
		}
		@Field(12) 
		public int fps_last_dts_idx() {
			return this.io.getIntField(this, 12);
		}
		@Field(12) 
		public info_struct fps_last_dts_idx(int fps_last_dts_idx) {
			this.io.setIntField(this, 12, fps_last_dts_idx);
			return this;
		}
		public info_struct() {
			super();
		}
		public info_struct(Pointer pointer) {
			super(pointer);
		}
	};
	public AVStream() {
		super();
	}
	public AVStream(Pointer pointer) {
		super(pointer);
	}
}
