package org.ffmpeg.avformat;
import org.bridj.BridJ;
import org.bridj.IntValuedEnum;
import org.bridj.Pointer;
import org.bridj.StructObject;
import org.bridj.ann.Array;
import org.bridj.ann.Field;
import org.bridj.ann.Library;
import org.bridj.ann.Struct;
import org.ffmpeg.avcodec.AVCodec;
import org.ffmpeg.avcodec.AvcodecLibrary.AVCodecID;
import org.ffmpeg.avformat.AvformatLibrary.AVDurationEstimationMethod;
import org.ffmpeg.avformat.AvformatLibrary.av_format_control_message;
import org.ffmpeg.avutil.AVClass;
import org.ffmpeg.avutil.AVDictionary;
import org.ffmpeg.avutil.AVRational;
import org.ffmpeg.util.AlignmentCustomizer;
/**
 * <i>native declaration : libavformat/avformat.h:682</i><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> or <a href="http://bridj.googlecode.com/">BridJ</a> .
 */
@Library("avformat") 
public class AVFormatContext extends StructObject {
	static {
		BridJ.register();
	}
	/**
	 * A class for logging and @ref avoptions. Set by avformat_alloc_context().<br>
	 * Exports (de)muxer private options if they exist.<br>
	 * C type : const AVClass*
	 */
	@Field(0) 
	public Pointer<AVClass > av_class() {
		return this.io.getPointerField(this, 0);
	}
	/**
	 * A class for logging and @ref avoptions. Set by avformat_alloc_context().<br>
	 * Exports (de)muxer private options if they exist.<br>
	 * C type : const AVClass*
	 */
	@Field(0) 
	public AVFormatContext av_class(Pointer<AVClass > av_class) {
		this.io.setPointerField(this, 0, av_class);
		return this;
	}
	/**
	 * The input container format.<br>
	 * * Demuxing only, set by avformat_open_input().<br>
	 * C type : AVInputFormat*
	 */
	@Field(1) 
	public Pointer<AVInputFormat > iformat() {
		return this.io.getPointerField(this, 1);
	}
	/**
	 * The input container format.<br>
	 * * Demuxing only, set by avformat_open_input().<br>
	 * C type : AVInputFormat*
	 */
	@Field(1) 
	public AVFormatContext iformat(Pointer<AVInputFormat > iformat) {
		this.io.setPointerField(this, 1, iformat);
		return this;
	}
	/**
	 * The output container format.<br>
	 * * Muxing only, must be set by the caller before avformat_write_header().<br>
	 * C type : AVOutputFormat*
	 */
	@Field(2) 
	public Pointer<AVOutputFormat > oformat() {
		return this.io.getPointerField(this, 2);
	}
	/**
	 * The output container format.<br>
	 * * Muxing only, must be set by the caller before avformat_write_header().<br>
	 * C type : AVOutputFormat*
	 */
	@Field(2) 
	public AVFormatContext oformat(Pointer<AVOutputFormat > oformat) {
		this.io.setPointerField(this, 2, oformat);
		return this;
	}
	/**
	 * Format private data. This is an AVOptions-enabled struct<br>
	 * if and only if iformat/oformat.priv_class is not NULL.<br>
	 * * - muxing: set by avformat_write_header()<br>
	 * - demuxing: set by avformat_open_input()<br>
	 * C type : void*
	 */
	@Field(3) 
	public Pointer<? > priv_data() {
		return this.io.getPointerField(this, 3);
	}
	/**
	 * Format private data. This is an AVOptions-enabled struct<br>
	 * if and only if iformat/oformat.priv_class is not NULL.<br>
	 * * - muxing: set by avformat_write_header()<br>
	 * - demuxing: set by avformat_open_input()<br>
	 * C type : void*
	 */
	@Field(3) 
	public AVFormatContext priv_data(Pointer<? > priv_data) {
		this.io.setPointerField(this, 3, priv_data);
		return this;
	}
	/**
	 * I/O context.<br>
	 * * - demuxing: either set by the user before avformat_open_input() (then<br>
	 *             the user must close it manually) or set by avformat_open_input().<br>
	 * - muxing: set by the user before avformat_write_header(). The caller must<br>
	 *           take care of closing / freeing the IO context.<br>
	 * * Do NOT set this field if AVFMT_NOFILE flag is set in<br>
	 * iformat/oformat.flags. In such a case, the (de)muxer will handle<br>
	 * I/O in some other way and this field will be NULL.<br>
	 * C type : AVIOContext*
	 */
	@Field(4) 
	public Pointer<AVIOContext > pb() {
		return this.io.getPointerField(this, 4);
	}
	/**
	 * I/O context.<br>
	 * * - demuxing: either set by the user before avformat_open_input() (then<br>
	 *             the user must close it manually) or set by avformat_open_input().<br>
	 * - muxing: set by the user before avformat_write_header(). The caller must<br>
	 *           take care of closing / freeing the IO context.<br>
	 * * Do NOT set this field if AVFMT_NOFILE flag is set in<br>
	 * iformat/oformat.flags. In such a case, the (de)muxer will handle<br>
	 * I/O in some other way and this field will be NULL.<br>
	 * C type : AVIOContext*
	 */
	@Field(4) 
	public AVFormatContext pb(Pointer<AVIOContext > pb) {
		this.io.setPointerField(this, 4, pb);
		return this;
	}
	/**
	 * Flags signalling stream properties. A combination of AVFMTCTX_*.<br>
	 * Set by libavformat.
	 */
	@Field(5) 
	public int ctx_flags() {
		return this.io.getIntField(this, 5);
	}
	/**
	 * Flags signalling stream properties. A combination of AVFMTCTX_*.<br>
	 * Set by libavformat.
	 */
	@Field(5) 
	public AVFormatContext ctx_flags(int ctx_flags) {
		this.io.setIntField(this, 5, ctx_flags);
		return this;
	}
	/**
	 * Number of elements in AVFormatContext.streams.<br>
	 * * Set by avformat_new_stream(), must not be modified by any other code.
	 */
	@Field(6) 
	public int nb_streams() {
		return this.io.getIntField(this, 6);
	}
	/**
	 * Number of elements in AVFormatContext.streams.<br>
	 * * Set by avformat_new_stream(), must not be modified by any other code.
	 */
	@Field(6) 
	public AVFormatContext nb_streams(int nb_streams) {
		this.io.setIntField(this, 6, nb_streams);
		return this;
	}
	/**
	 * A list of all streams in the file. New streams are created with<br>
	 * avformat_new_stream().<br>
	 * * - demuxing: streams are created by libavformat in avformat_open_input().<br>
	 *             If AVFMTCTX_NOHEADER is set in ctx_flags, then new streams may also<br>
	 *             appear in av_read_frame().<br>
	 * - muxing: streams are created by the user before avformat_write_header().<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : AVStream**
	 */
	@Field(7) 
	public Pointer<Pointer<AVStream > > streams() {
		return this.io.getPointerField(this, 7);
	}
	/**
	 * A list of all streams in the file. New streams are created with<br>
	 * avformat_new_stream().<br>
	 * * - demuxing: streams are created by libavformat in avformat_open_input().<br>
	 *             If AVFMTCTX_NOHEADER is set in ctx_flags, then new streams may also<br>
	 *             appear in av_read_frame().<br>
	 * - muxing: streams are created by the user before avformat_write_header().<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : AVStream**
	 */
	@Field(7) 
	public AVFormatContext streams(Pointer<Pointer<AVStream > > streams) {
		this.io.setPointerField(this, 7, streams);
		return this;
	}
	/**
	 * input or output filename<br>
	 * * - demuxing: set by avformat_open_input()<br>
	 * - muxing: may be set by the caller before avformat_write_header()<br>
	 * C type : char[1024]
	 */
	@Array({1024}) 
	@Field(8) 
	public Pointer<Byte > filename() {
		return this.io.getPointerField(this, 8);
	}
	/**
	 * Position of the first frame of the component, in<br>
	 * AV_TIME_BASE fractional seconds. NEVER set this value directly:<br>
	 * It is deduced from the AVStream values.<br>
	 * * Demuxing only, set by libavformat.
	 */
	@Field(9) 
	public long start_time() {
		return this.io.getLongField(this, 9);
	}
	/**
	 * Position of the first frame of the component, in<br>
	 * AV_TIME_BASE fractional seconds. NEVER set this value directly:<br>
	 * It is deduced from the AVStream values.<br>
	 * * Demuxing only, set by libavformat.
	 */
	@Field(9) 
	public AVFormatContext start_time(long start_time) {
		this.io.setLongField(this, 9, start_time);
		return this;
	}
	/**
	 * Duration of the stream, in AV_TIME_BASE fractional<br>
	 * seconds. Only set this value if you know none of the individual stream<br>
	 * durations and also do not set any of them. This is deduced from the<br>
	 * AVStream values if not set.<br>
	 * * Demuxing only, set by libavformat.
	 */
	@Field(10) 
	public long duration() {
		return this.io.getLongField(this, 10);
	}
	/**
	 * Duration of the stream, in AV_TIME_BASE fractional<br>
	 * seconds. Only set this value if you know none of the individual stream<br>
	 * durations and also do not set any of them. This is deduced from the<br>
	 * AVStream values if not set.<br>
	 * * Demuxing only, set by libavformat.
	 */
	@Field(10) 
	public AVFormatContext duration(long duration) {
		this.io.setLongField(this, 10, duration);
		return this;
	}
	/**
	 * Total stream bitrate in bit/s, 0 if not<br>
	 * available. Never set it directly if the file_size and the<br>
	 * duration are known as FFmpeg can compute it automatically.
	 */
	@Field(11) 
	public int bit_rate() {
		return this.io.getIntField(this, 11);
	}
	/**
	 * Total stream bitrate in bit/s, 0 if not<br>
	 * available. Never set it directly if the file_size and the<br>
	 * duration are known as FFmpeg can compute it automatically.
	 */
	@Field(11) 
	public AVFormatContext bit_rate(int bit_rate) {
		this.io.setIntField(this, 11, bit_rate);
		return this;
	}
	@Field(12) 
	public int packet_size() {
		return this.io.getIntField(this, 12);
	}
	@Field(12) 
	public AVFormatContext packet_size(int packet_size) {
		this.io.setIntField(this, 12, packet_size);
		return this;
	}
	@Field(13) 
	public int max_delay() {
		return this.io.getIntField(this, 13);
	}
	@Field(13) 
	public AVFormatContext max_delay(int max_delay) {
		this.io.setIntField(this, 13, max_delay);
		return this;
	}
	/**
	 * Flags modifying the (de)muxer behaviour. A combination of AVFMT_FLAG_*.<br>
	 * Set by the user before avformat_open_input() / avformat_write_header().
	 */
	@Field(14) 
	public int flags() {
		return this.io.getIntField(this, 14);
	}
	/**
	 * Flags modifying the (de)muxer behaviour. A combination of AVFMT_FLAG_*.<br>
	 * Set by the user before avformat_open_input() / avformat_write_header().
	 */
	@Field(14) 
	public AVFormatContext flags(int flags) {
		this.io.setIntField(this, 14, flags);
		return this;
	}
	/**
	 * Maximum size of the data read from input for determining<br>
	 * the input container format.<br>
	 * Demuxing only, set by the caller before avformat_open_input().
	 */
	@Field(15) 
	public int probesize() {
		return this.io.getIntField(this, 15);
	}
	/**
	 * Maximum size of the data read from input for determining<br>
	 * the input container format.<br>
	 * Demuxing only, set by the caller before avformat_open_input().
	 */
	@Field(15) 
	public AVFormatContext probesize(int probesize) {
		this.io.setIntField(this, 15, probesize);
		return this;
	}
	@Field(16) 
	public int max_analyze_duration() {
		return this.io.getIntField(this, 16);
	}
	@Field(16) 
	public AVFormatContext max_analyze_duration(int max_analyze_duration) {
		this.io.setIntField(this, 16, max_analyze_duration);
		return this;
	}
	/** C type : const uint8_t* */
	@Field(17) 
	public Pointer<Byte > key() {
		return this.io.getPointerField(this, 17);
	}
	/** C type : const uint8_t* */
	@Field(17) 
	public AVFormatContext key(Pointer<Byte > key) {
		this.io.setPointerField(this, 17, key);
		return this;
	}
	@Field(18) 
	public int keylen() {
		return this.io.getIntField(this, 18);
	}
	@Field(18) 
	public AVFormatContext keylen(int keylen) {
		this.io.setIntField(this, 18, keylen);
		return this;
	}
	@Field(19) 
	public int nb_programs() {
		return this.io.getIntField(this, 19);
	}
	@Field(19) 
	public AVFormatContext nb_programs(int nb_programs) {
		this.io.setIntField(this, 19, nb_programs);
		return this;
	}
	/** C type : AVProgram** */
	@Field(20) 
	public Pointer<Pointer<AVProgram > > programs() {
		return this.io.getPointerField(this, 20);
	}
	/** C type : AVProgram** */
	@Field(20) 
	public AVFormatContext programs(Pointer<Pointer<AVProgram > > programs) {
		this.io.setPointerField(this, 20, programs);
		return this;
	}
	/**
	 * Forced video codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(21) 
	public IntValuedEnum<AVCodecID > video_codec_id() {
		return this.io.getEnumField(this, 21);
	}
	/**
	 * Forced video codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(21) 
	public AVFormatContext video_codec_id(IntValuedEnum<AVCodecID > video_codec_id) {
		this.io.setEnumField(this, 21, video_codec_id);
		return this;
	}
	/**
	 * Forced audio codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(22) 
	public IntValuedEnum<AVCodecID > audio_codec_id() {
		return this.io.getEnumField(this, 22);
	}
	/**
	 * Forced audio codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(22) 
	public AVFormatContext audio_codec_id(IntValuedEnum<AVCodecID > audio_codec_id) {
		this.io.setEnumField(this, 22, audio_codec_id);
		return this;
	}
	/**
	 * Forced subtitle codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(23) 
	public IntValuedEnum<AVCodecID > subtitle_codec_id() {
		return this.io.getEnumField(this, 23);
	}
	/**
	 * Forced subtitle codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * C type : AVCodecID
	 */
	@Field(23) 
	public AVFormatContext subtitle_codec_id(IntValuedEnum<AVCodecID > subtitle_codec_id) {
		this.io.setEnumField(this, 23, subtitle_codec_id);
		return this;
	}
	/**
	 * Maximum amount of memory in bytes to use for the index of each stream.<br>
	 * If the index exceeds this size, entries will be discarded as<br>
	 * needed to maintain a smaller size. This can lead to slower or less<br>
	 * accurate seeking (depends on demuxer).<br>
	 * Demuxers for which a full in-memory index is mandatory will ignore<br>
	 * this.<br>
	 * - muxing: unused<br>
	 * - demuxing: set by user
	 */
	@Field(24) 
	public int max_index_size() {
		return this.io.getIntField(this, 24);
	}
	/**
	 * Maximum amount of memory in bytes to use for the index of each stream.<br>
	 * If the index exceeds this size, entries will be discarded as<br>
	 * needed to maintain a smaller size. This can lead to slower or less<br>
	 * accurate seeking (depends on demuxer).<br>
	 * Demuxers for which a full in-memory index is mandatory will ignore<br>
	 * this.<br>
	 * - muxing: unused<br>
	 * - demuxing: set by user
	 */
	@Field(24) 
	public AVFormatContext max_index_size(int max_index_size) {
		this.io.setIntField(this, 24, max_index_size);
		return this;
	}
	/**
	 * Maximum amount of memory in bytes to use for buffering frames<br>
	 * obtained from realtime capture devices.
	 */
	@Field(25) 
	public int max_picture_buffer() {
		return this.io.getIntField(this, 25);
	}
	/**
	 * Maximum amount of memory in bytes to use for buffering frames<br>
	 * obtained from realtime capture devices.
	 */
	@Field(25) 
	public AVFormatContext max_picture_buffer(int max_picture_buffer) {
		this.io.setIntField(this, 25, max_picture_buffer);
		return this;
	}
	/**
	 * Number of chapters in AVChapter array.<br>
	 * When muxing, chapters are normally written in the file header,<br>
	 * so nb_chapters should normally be initialized before write_header<br>
	 * is called. Some muxers (e.g. mov and mkv) can also write chapters<br>
	 * in the trailer.  To write chapters in the trailer, nb_chapters<br>
	 * must be zero when write_header is called and non-zero when<br>
	 * write_trailer is called.<br>
	 * - muxing: set by user<br>
	 * - demuxing: set by libavformat
	 */
	@Field(26) 
	public int nb_chapters() {
		return this.io.getIntField(this, 26);
	}
	/**
	 * Number of chapters in AVChapter array.<br>
	 * When muxing, chapters are normally written in the file header,<br>
	 * so nb_chapters should normally be initialized before write_header<br>
	 * is called. Some muxers (e.g. mov and mkv) can also write chapters<br>
	 * in the trailer.  To write chapters in the trailer, nb_chapters<br>
	 * must be zero when write_header is called and non-zero when<br>
	 * write_trailer is called.<br>
	 * - muxing: set by user<br>
	 * - demuxing: set by libavformat
	 */
	@Field(26) 
	public AVFormatContext nb_chapters(int nb_chapters) {
		this.io.setIntField(this, 26, nb_chapters);
		return this;
	}
	/** C type : AVChapter** */
	@Field(27) 
	public Pointer<Pointer<AVChapter > > chapters() {
		return this.io.getPointerField(this, 27);
	}
	/** C type : AVChapter** */
	@Field(27) 
	public AVFormatContext chapters(Pointer<Pointer<AVChapter > > chapters) {
		this.io.setPointerField(this, 27, chapters);
		return this;
	}
	/**
	 * Metadata that applies to the whole file.<br>
	 * * - demuxing: set by libavformat in avformat_open_input()<br>
	 * - muxing: may be set by the caller before avformat_write_header()<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : AVDictionary*
	 */
	@Field(28) 
	public Pointer<AVDictionary > metadata() {
		return this.io.getPointerField(this, 28);
	}
	/**
	 * Metadata that applies to the whole file.<br>
	 * * - demuxing: set by libavformat in avformat_open_input()<br>
	 * - muxing: may be set by the caller before avformat_write_header()<br>
	 * * Freed by libavformat in avformat_free_context().<br>
	 * C type : AVDictionary*
	 */
	@Field(28) 
	public AVFormatContext metadata(Pointer<AVDictionary > metadata) {
		this.io.setPointerField(this, 28, metadata);
		return this;
	}
	/**
	 * Start time of the stream in real world time, in microseconds<br>
	 * since the Unix epoch (00:00 1st January 1970). That is, pts=0 in the<br>
	 * stream was captured at this real world time.<br>
	 * - muxing: Set by the caller before avformat_write_header(). If set to<br>
	 *           either 0 or AV_NOPTS_VALUE, then the current wall-time will<br>
	 *           be used.<br>
	 * - demuxing: Set by libavformat. AV_NOPTS_VALUE if unknown. Note that<br>
	 *             the value may become known after some number of frames<br>
	 *             have been received.
	 */
	@Field(29) 
	public long start_time_realtime() {
		return this.io.getLongField(this, 29);
	}
	/**
	 * Start time of the stream in real world time, in microseconds<br>
	 * since the Unix epoch (00:00 1st January 1970). That is, pts=0 in the<br>
	 * stream was captured at this real world time.<br>
	 * - muxing: Set by the caller before avformat_write_header(). If set to<br>
	 *           either 0 or AV_NOPTS_VALUE, then the current wall-time will<br>
	 *           be used.<br>
	 * - demuxing: Set by libavformat. AV_NOPTS_VALUE if unknown. Note that<br>
	 *             the value may become known after some number of frames<br>
	 *             have been received.
	 */
	@Field(29) 
	public AVFormatContext start_time_realtime(long start_time_realtime) {
		this.io.setLongField(this, 29, start_time_realtime);
		return this;
	}
	/**
	 * The number of frames used for determining the framerate in<br>
	 * avformat_find_stream_info().<br>
	 * Demuxing only, set by the caller before avformat_find_stream_info().
	 */
	@Field(30) 
	public int fps_probe_size() {
		return this.io.getIntField(this, 30);
	}
	/**
	 * The number of frames used for determining the framerate in<br>
	 * avformat_find_stream_info().<br>
	 * Demuxing only, set by the caller before avformat_find_stream_info().
	 */
	@Field(30) 
	public AVFormatContext fps_probe_size(int fps_probe_size) {
		this.io.setIntField(this, 30, fps_probe_size);
		return this;
	}
	/**
	 * Error recognition; higher values will detect more errors but may<br>
	 * misdetect some more or less valid parts as errors.<br>
	 * Demuxing only, set by the caller before avformat_open_input().
	 */
	@Field(31) 
	public int error_recognition() {
		return this.io.getIntField(this, 31);
	}
	/**
	 * Error recognition; higher values will detect more errors but may<br>
	 * misdetect some more or less valid parts as errors.<br>
	 * Demuxing only, set by the caller before avformat_open_input().
	 */
	@Field(31) 
	public AVFormatContext error_recognition(int error_recognition) {
		this.io.setIntField(this, 31, error_recognition);
		return this;
	}
	/**
	 * Custom interrupt callbacks for the I/O layer.<br>
	 * * demuxing: set by the user before avformat_open_input().<br>
	 * muxing: set by the user before avformat_write_header()<br>
	 * (mainly useful for AVFMT_NOFILE formats). The callback<br>
	 * should also be passed to avio_open2() if it's used to<br>
	 * open the file.<br>
	 * C type : AVIOInterruptCB
	 */
	@Field(32) 
	public AVIOInterruptCB interrupt_callback() {
		return this.io.getNativeObjectField(this, 32);
	}
	/**
	 * Custom interrupt callbacks for the I/O layer.<br>
	 * * demuxing: set by the user before avformat_open_input().<br>
	 * muxing: set by the user before avformat_write_header()<br>
	 * (mainly useful for AVFMT_NOFILE formats). The callback<br>
	 * should also be passed to avio_open2() if it's used to<br>
	 * open the file.<br>
	 * C type : AVIOInterruptCB
	 */
	@Field(32) 
	public AVFormatContext interrupt_callback(AVIOInterruptCB interrupt_callback) {
		this.io.setNativeObjectField(this, 32, interrupt_callback);
		return this;
	}
	/** Flags to enable debugging. */
	@Field(33) 
	public int debug() {
		return this.io.getIntField(this, 33);
	}
	/** Flags to enable debugging. */
	@Field(33) 
	public AVFormatContext debug(int debug) {
		this.io.setIntField(this, 33, debug);
		return this;
	}
	/**
	 * Maximum buffering duration for interleaving.<br>
	 * * To ensure all the streams are interleaved correctly,<br>
	 * av_interleaved_write_frame() will wait until it has at least one packet<br>
	 * for each stream before actually writing any packets to the output file.<br>
	 * When some streams are "sparse" (i.e. there are large gaps between<br>
	 * successive packets), this can result in excessive buffering.<br>
	 * * This field specifies the maximum difference between the timestamps of the<br>
	 * first and the last packet in the muxing queue, above which libavformat<br>
	 * will output a packet regardless of whether it has queued a packet for all<br>
	 * the streams.<br>
	 * * Muxing only, set by the caller before avformat_write_header().
	 */
	@Field(34) 
	public long max_interleave_delta() {
		return this.io.getLongField(this, 34);
	}
	/**
	 * Maximum buffering duration for interleaving.<br>
	 * * To ensure all the streams are interleaved correctly,<br>
	 * av_interleaved_write_frame() will wait until it has at least one packet<br>
	 * for each stream before actually writing any packets to the output file.<br>
	 * When some streams are "sparse" (i.e. there are large gaps between<br>
	 * successive packets), this can result in excessive buffering.<br>
	 * * This field specifies the maximum difference between the timestamps of the<br>
	 * first and the last packet in the muxing queue, above which libavformat<br>
	 * will output a packet regardless of whether it has queued a packet for all<br>
	 * the streams.<br>
	 * * Muxing only, set by the caller before avformat_write_header().
	 */
	@Field(34) 
	public AVFormatContext max_interleave_delta(long max_interleave_delta) {
		this.io.setLongField(this, 34, max_interleave_delta);
		return this;
	}
	/**
	 * Allow non-standard and experimental extension<br>
	 * @see AVCodecContext.strict_std_compliance
	 */
	@Field(35) 
	public int strict_std_compliance() {
		return this.io.getIntField(this, 35);
	}
	/**
	 * Allow non-standard and experimental extension<br>
	 * @see AVCodecContext.strict_std_compliance
	 */
	@Field(35) 
	public AVFormatContext strict_std_compliance(int strict_std_compliance) {
		this.io.setIntField(this, 35, strict_std_compliance);
		return this;
	}
	/**
	 * Transport stream id.<br>
	 * This will be moved into demuxer private options. Thus no API/ABI compatibility
	 */
	@Field(36) 
	public int ts_id() {
		return this.io.getIntField(this, 36);
	}
	/**
	 * Transport stream id.<br>
	 * This will be moved into demuxer private options. Thus no API/ABI compatibility
	 */
	@Field(36) 
	public AVFormatContext ts_id(int ts_id) {
		this.io.setIntField(this, 36, ts_id);
		return this;
	}
	/**
	 * Audio preload in microseconds.<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(37) 
	public int audio_preload() {
		return this.io.getIntField(this, 37);
	}
	/**
	 * Audio preload in microseconds.<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(37) 
	public AVFormatContext audio_preload(int audio_preload) {
		this.io.setIntField(this, 37, audio_preload);
		return this;
	}
	/**
	 * Max chunk time in microseconds.<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(38) 
	public int max_chunk_duration() {
		return this.io.getIntField(this, 38);
	}
	/**
	 * Max chunk time in microseconds.<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(38) 
	public AVFormatContext max_chunk_duration(int max_chunk_duration) {
		this.io.setIntField(this, 38, max_chunk_duration);
		return this;
	}
	/**
	 * Max chunk size in bytes<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(39) 
	public int max_chunk_size() {
		return this.io.getIntField(this, 39);
	}
	/**
	 * Max chunk size in bytes<br>
	 * Note, not all formats support this and unpredictable things may happen if it is used when not supported.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(39) 
	public AVFormatContext max_chunk_size(int max_chunk_size) {
		this.io.setIntField(this, 39, max_chunk_size);
		return this;
	}
	/**
	 * forces the use of wallclock timestamps as pts/dts of packets<br>
	 * This has undefined results in the presence of B frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(40) 
	public int use_wallclock_as_timestamps() {
		return this.io.getIntField(this, 40);
	}
	/**
	 * forces the use of wallclock timestamps as pts/dts of packets<br>
	 * This has undefined results in the presence of B frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(40) 
	public AVFormatContext use_wallclock_as_timestamps(int use_wallclock_as_timestamps) {
		this.io.setIntField(this, 40, use_wallclock_as_timestamps);
		return this;
	}
	/**
	 * Avoid negative timestamps during muxing.<br>
	 *  0 -> allow negative timestamps<br>
	 *  1 -> avoid negative timestamps<br>
	 * -1 -> choose automatically (default)<br>
	 * Note, this only works when interleave_packet_per_dts is in use.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(41) 
	public int avoid_negative_ts() {
		return this.io.getIntField(this, 41);
	}
	/**
	 * Avoid negative timestamps during muxing.<br>
	 *  0 -> allow negative timestamps<br>
	 *  1 -> avoid negative timestamps<br>
	 * -1 -> choose automatically (default)<br>
	 * Note, this only works when interleave_packet_per_dts is in use.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(41) 
	public AVFormatContext avoid_negative_ts(int avoid_negative_ts) {
		this.io.setIntField(this, 41, avoid_negative_ts);
		return this;
	}
	/**
	 * avio flags, used to force AVIO_FLAG_DIRECT.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(42) 
	public int avio_flags() {
		return this.io.getIntField(this, 42);
	}
	/**
	 * avio flags, used to force AVIO_FLAG_DIRECT.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(42) 
	public AVFormatContext avio_flags(int avio_flags) {
		this.io.setIntField(this, 42, avio_flags);
		return this;
	}
	/**
	 * The duration field can be estimated through various ways, and this field can be used<br>
	 * to know how the duration was estimated.<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user via AVOptions (NO direct access)<br>
	 * C type : AVDurationEstimationMethod
	 */
	@Field(43) 
	public IntValuedEnum<AVDurationEstimationMethod > duration_estimation_method() {
		return this.io.getEnumField(this, 43);
	}
	/**
	 * The duration field can be estimated through various ways, and this field can be used<br>
	 * to know how the duration was estimated.<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user via AVOptions (NO direct access)<br>
	 * C type : AVDurationEstimationMethod
	 */
	@Field(43) 
	public AVFormatContext duration_estimation_method(IntValuedEnum<AVDurationEstimationMethod > duration_estimation_method) {
		this.io.setEnumField(this, 43, duration_estimation_method);
		return this;
	}
	/**
	 * Skip initial bytes when opening stream<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(44) 
	public long skip_initial_bytes() {
		return this.io.getLongField(this, 44);
	}
	/**
	 * Skip initial bytes when opening stream<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(44) 
	public AVFormatContext skip_initial_bytes(long skip_initial_bytes) {
		this.io.setLongField(this, 44, skip_initial_bytes);
		return this;
	}
	/**
	 * Correct single timestamp overflows<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(45) 
	public int correct_ts_overflow() {
		return this.io.getIntField(this, 45);
	}
	/**
	 * Correct single timestamp overflows<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(45) 
	public AVFormatContext correct_ts_overflow(int correct_ts_overflow) {
		this.io.setIntField(this, 45, correct_ts_overflow);
		return this;
	}
	/**
	 * Force seeking to any (also non key) frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(46) 
	public int seek2any() {
		return this.io.getIntField(this, 46);
	}
	/**
	 * Force seeking to any (also non key) frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user via AVOptions (NO direct access)
	 */
	@Field(46) 
	public AVFormatContext seek2any(int seek2any) {
		this.io.setIntField(this, 46, seek2any);
		return this;
	}
	/**
	 * Flush the I/O context after each packet.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(47) 
	public int flush_packets() {
		return this.io.getIntField(this, 47);
	}
	/**
	 * Flush the I/O context after each packet.<br>
	 * - encoding: Set by user via AVOptions (NO direct access)<br>
	 * - decoding: unused
	 */
	@Field(47) 
	public AVFormatContext flush_packets(int flush_packets) {
		this.io.setIntField(this, 47, flush_packets);
		return this;
	}
	/**
	 * format probing score.<br>
	 * The maximal score is AVPROBE_SCORE_MAX, its set when the demuxer probes<br>
	 * the format.<br>
	 * - encoding: unused<br>
	 * - decoding: set by avformat, read by user via av_format_get_probe_score() (NO direct access)
	 */
	@Field(48) 
	public int probe_score() {
		return this.io.getIntField(this, 48);
	}
	/**
	 * format probing score.<br>
	 * The maximal score is AVPROBE_SCORE_MAX, its set when the demuxer probes<br>
	 * the format.<br>
	 * - encoding: unused<br>
	 * - decoding: set by avformat, read by user via av_format_get_probe_score() (NO direct access)
	 */
	@Field(48) 
	public AVFormatContext probe_score(int probe_score) {
		this.io.setIntField(this, 48, probe_score);
		return this;
	}
	/**
	 * number of bytes to read maximally to identify format.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user through AVOPtions (NO direct access)
	 */
	@Field(49) 
	public int format_probesize() {
		return this.io.getIntField(this, 49);
	}
	/**
	 * number of bytes to read maximally to identify format.<br>
	 * - encoding: unused<br>
	 * - decoding: set by user through AVOPtions (NO direct access)
	 */
	@Field(49) 
	public AVFormatContext format_probesize(int format_probesize) {
		this.io.setIntField(this, 49, format_probesize);
		return this;
	}
	/**
	 * This buffer is only needed when packets were already buffered but<br>
	 * not decoded, for example to get the codec parameters in MPEG<br>
	 * streams.<br>
	 * C type : AVPacketList*
	 */
	@Field(50) 
	public Pointer<AVPacketList > packet_buffer() {
		return this.io.getPointerField(this, 50);
	}
	/**
	 * This buffer is only needed when packets were already buffered but<br>
	 * not decoded, for example to get the codec parameters in MPEG<br>
	 * streams.<br>
	 * C type : AVPacketList*
	 */
	@Field(50) 
	public AVFormatContext packet_buffer(Pointer<AVPacketList > packet_buffer) {
		this.io.setPointerField(this, 50, packet_buffer);
		return this;
	}
	/** C type : AVPacketList* */
	@Field(51) 
	public Pointer<AVPacketList > packet_buffer_end() {
		return this.io.getPointerField(this, 51);
	}
	/** C type : AVPacketList* */
	@Field(51) 
	public AVFormatContext packet_buffer_end(Pointer<AVPacketList > packet_buffer_end) {
		this.io.setPointerField(this, 51, packet_buffer_end);
		return this;
	}
	/**
	 * av_seek_frame() support<br>
	 * < offset of the first packet
	 */
	@Field(52) 
	public long data_offset() {
		return this.io.getLongField(this, 52);
	}
	/**
	 * av_seek_frame() support<br>
	 * < offset of the first packet
	 */
	@Field(52) 
	public AVFormatContext data_offset(long data_offset) {
		this.io.setLongField(this, 52, data_offset);
		return this;
	}
	/**
	 * Raw packets from the demuxer, prior to parsing and decoding.<br>
	 * This buffer is used for buffering packets until the codec can<br>
	 * be identified, as parsing cannot be done without knowing the<br>
	 * codec.<br>
	 * C type : AVPacketList*
	 */
	@Field(53) 
	public Pointer<AVPacketList > raw_packet_buffer() {
		return this.io.getPointerField(this, 53);
	}
	/**
	 * Raw packets from the demuxer, prior to parsing and decoding.<br>
	 * This buffer is used for buffering packets until the codec can<br>
	 * be identified, as parsing cannot be done without knowing the<br>
	 * codec.<br>
	 * C type : AVPacketList*
	 */
	@Field(53) 
	public AVFormatContext raw_packet_buffer(Pointer<AVPacketList > raw_packet_buffer) {
		this.io.setPointerField(this, 53, raw_packet_buffer);
		return this;
	}
	/** C type : AVPacketList* */
	@Field(54) 
	public Pointer<AVPacketList > raw_packet_buffer_end() {
		return this.io.getPointerField(this, 54);
	}
	/** C type : AVPacketList* */
	@Field(54) 
	public AVFormatContext raw_packet_buffer_end(Pointer<AVPacketList > raw_packet_buffer_end) {
		this.io.setPointerField(this, 54, raw_packet_buffer_end);
		return this;
	}
	/**
	 * Packets split by the parser get queued here.<br>
	 * C type : AVPacketList*
	 */
	@Field(55) 
	public Pointer<AVPacketList > parse_queue() {
		return this.io.getPointerField(this, 55);
	}
	/**
	 * Packets split by the parser get queued here.<br>
	 * C type : AVPacketList*
	 */
	@Field(55) 
	public AVFormatContext parse_queue(Pointer<AVPacketList > parse_queue) {
		this.io.setPointerField(this, 55, parse_queue);
		return this;
	}
	/** C type : AVPacketList* */
	@Field(56) 
	public Pointer<AVPacketList > parse_queue_end() {
		return this.io.getPointerField(this, 56);
	}
	/** C type : AVPacketList* */
	@Field(56) 
	public AVFormatContext parse_queue_end(Pointer<AVPacketList > parse_queue_end) {
		this.io.setPointerField(this, 56, parse_queue_end);
		return this;
	}
	@Field(57) 
	public int raw_packet_buffer_remaining_size() {
		return this.io.getIntField(this, 57);
	}
	@Field(57) 
	public AVFormatContext raw_packet_buffer_remaining_size(int raw_packet_buffer_remaining_size) {
		this.io.setIntField(this, 57, raw_packet_buffer_remaining_size);
		return this;
	}
	/**
	 * Offset to remap timestamps to be non-negative.<br>
	 * Expressed in timebase units.<br>
	 * @see AVStream.mux_ts_offset
	 */
	@Field(58) 
	public long offset() {
		return this.io.getLongField(this, 58);
	}
	/**
	 * Offset to remap timestamps to be non-negative.<br>
	 * Expressed in timebase units.<br>
	 * @see AVStream.mux_ts_offset
	 */
	@Field(58) 
	public AVFormatContext offset(long offset) {
		this.io.setLongField(this, 58, offset);
		return this;
	}
	/**
	 * Timebase for the timestamp offset.<br>
	 * C type : AVRational
	 */
	@Field(59) 
	public AVRational offset_timebase() {
		return this.io.getNativeObjectField(this, 59);
	}
	/**
	 * Timebase for the timestamp offset.<br>
	 * C type : AVRational
	 */
	@Field(59) 
	public AVFormatContext offset_timebase(AVRational offset_timebase) {
		this.io.setNativeObjectField(this, 59, offset_timebase);
		return this;
	}
	/**
	 * An opaque field for libavformat internal usage.<br>
	 * Must not be accessed in any way by callers.<br>
	 * C type : AVFormatInternal*
	 */
	@Field(60) 
	public Pointer<AVFormatInternal > internal() {
		return this.io.getPointerField(this, 60);
	}
	/**
	 * An opaque field for libavformat internal usage.<br>
	 * Must not be accessed in any way by callers.<br>
	 * C type : AVFormatInternal*
	 */
	@Field(60) 
	public AVFormatContext internal(Pointer<AVFormatInternal > internal) {
		this.io.setPointerField(this, 60, internal);
		return this;
	}
	/**
	 * IO repositioned flag.<br>
	 * This is set by avformat when the underlaying IO context read pointer<br>
	 * is repositioned, for example when doing byte based seeking.<br>
	 * Demuxers can use the flag to detect such changes.
	 */
	@Field(61) 
	public int io_repositioned() {
		return this.io.getIntField(this, 61);
	}
	/**
	 * IO repositioned flag.<br>
	 * This is set by avformat when the underlaying IO context read pointer<br>
	 * is repositioned, for example when doing byte based seeking.<br>
	 * Demuxers can use the flag to detect such changes.
	 */
	@Field(61) 
	public AVFormatContext io_repositioned(int io_repositioned) {
		this.io.setIntField(this, 61, io_repositioned);
		return this;
	}
	/**
	 * Forced video codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user via av_format_set_video_codec (NO direct access).<br>
	 * C type : AVCodec*
	 */
	@Field(62) 
	public Pointer<AVCodec > video_codec() {
		return this.io.getPointerField(this, 62);
	}
	/**
	 * Forced video codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user via av_format_set_video_codec (NO direct access).<br>
	 * C type : AVCodec*
	 */
	@Field(62) 
	public AVFormatContext video_codec(Pointer<AVCodec > video_codec) {
		this.io.setPointerField(this, 62, video_codec);
		return this;
	}
	/**
	 * Forced audio codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user via av_format_set_audio_codec (NO direct access).<br>
	 * C type : AVCodec*
	 */
	@Field(63) 
	public Pointer<AVCodec > audio_codec() {
		return this.io.getPointerField(this, 63);
	}
	/**
	 * Forced audio codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user via av_format_set_audio_codec (NO direct access).<br>
	 * C type : AVCodec*
	 */
	@Field(63) 
	public AVFormatContext audio_codec(Pointer<AVCodec > audio_codec) {
		this.io.setPointerField(this, 63, audio_codec);
		return this;
	}
	/**
	 * Forced subtitle codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user via av_format_set_subtitle_codec (NO direct access).<br>
	 * C type : AVCodec*
	 */
	@Field(64) 
	public Pointer<AVCodec > subtitle_codec() {
		return this.io.getPointerField(this, 64);
	}
	/**
	 * Forced subtitle codec.<br>
	 * This allows forcing a specific decoder, even when there are multiple with<br>
	 * the same codec_id.<br>
	 * Demuxing: Set by user via av_format_set_subtitle_codec (NO direct access).<br>
	 * C type : AVCodec*
	 */
	@Field(64) 
	public AVFormatContext subtitle_codec(Pointer<AVCodec > subtitle_codec) {
		this.io.setPointerField(this, 64, subtitle_codec);
		return this;
	}
	/**
	 * Number of bytes to be written as padding in a metadata header.<br>
	 * Demuxing: Unused.<br>
	 * Muxing: Set by user via av_format_set_metadata_header_padding.
	 */
	@Field(65) 
	public int metadata_header_padding() {
		return this.io.getIntField(this, 65);
	}
	/**
	 * Number of bytes to be written as padding in a metadata header.<br>
	 * Demuxing: Unused.<br>
	 * Muxing: Set by user via av_format_set_metadata_header_padding.
	 */
	@Field(65) 
	public AVFormatContext metadata_header_padding(int metadata_header_padding) {
		this.io.setIntField(this, 65, metadata_header_padding);
		return this;
	}
	/**
	 * User data.<br>
	 * This is a place for some private data of the user.<br>
	 * Mostly usable with control_message_cb or any future callbacks in device's context.<br>
	 * C type : void*
	 */
	@Field(66) 
	public Pointer<? > opaque() {
		return this.io.getPointerField(this, 66);
	}
	/**
	 * User data.<br>
	 * This is a place for some private data of the user.<br>
	 * Mostly usable with control_message_cb or any future callbacks in device's context.<br>
	 * C type : void*
	 */
	@Field(66) 
	public AVFormatContext opaque(Pointer<? > opaque) {
		this.io.setPointerField(this, 66, opaque);
		return this;
	}
	/**
	 * Callback used by devices to communicate with application.<br>
	 * C type : av_format_control_message
	 */
	@Field(67) 
	public Pointer<av_format_control_message > control_message_cb() {
		return this.io.getPointerField(this, 67);
	}
	/**
	 * Callback used by devices to communicate with application.<br>
	 * C type : av_format_control_message
	 */
	@Field(67) 
	public AVFormatContext control_message_cb(Pointer<av_format_control_message > control_message_cb) {
		this.io.setPointerField(this, 67, control_message_cb);
		return this;
	}
	/**
	 * Output timestamp offset, in microseconds.<br>
	 * Muxing: set by user via AVOptions (NO direct access)
	 */
	@Field(68) 
	public long output_ts_offset() {
		return this.io.getLongField(this, 68);
	}
	/**
	 * Output timestamp offset, in microseconds.<br>
	 * Muxing: set by user via AVOptions (NO direct access)
	 */
	@Field(68) 
	public AVFormatContext output_ts_offset(long output_ts_offset) {
		this.io.setLongField(this, 68, output_ts_offset);
		return this;
	}
	/**
	 * Maximum duration (in AV_TIME_BASE units) of the data read<br>
	 * from input in avformat_find_stream_info().<br>
	 * Demuxing only, set by the caller before avformat_find_stream_info()<br>
	 * via AVOptions (NO direct access).<br>
	 * Can be set to 0 to let avformat choose using a heuristic.
	 */
	@Field(69) 
	public long max_analyze_duration2() {
		return this.io.getLongField(this, 69);
	}
	/**
	 * Maximum duration (in AV_TIME_BASE units) of the data read<br>
	 * from input in avformat_find_stream_info().<br>
	 * Demuxing only, set by the caller before avformat_find_stream_info()<br>
	 * via AVOptions (NO direct access).<br>
	 * Can be set to 0 to let avformat choose using a heuristic.
	 */
	@Field(69) 
	public AVFormatContext max_analyze_duration2(long max_analyze_duration2) {
		this.io.setLongField(this, 69, max_analyze_duration2);
		return this;
	}
	@Struct(customizer=AlignmentCustomizer.class)
	public AVFormatContext() {
		super();
	}
	@Struct(customizer=AlignmentCustomizer.class)
	public AVFormatContext(Pointer pointer) {
		super(pointer);
	}
}
