package org.ffmpeg.avcodec;
import java.util.List;
import org.bridj.BridJ;
import org.bridj.Callback;
import org.bridj.Pointer;
import org.bridj.StructFieldDescription;
import org.bridj.StructObject;
import org.bridj.ann.Alignment;
import org.bridj.ann.Field;
import org.bridj.ann.Library;
import org.bridj.ann.Ptr;
import org.bridj.ann.Struct;
import org.ffmpeg.avutil.AVBufferRef;
import org.ffmpeg.util.AlignmentCustomizer;
/**
 * <i>native declaration : ./libavcodec/avcodec.h:327</i><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> or <a href="http://bridj.googlecode.com/">BridJ</a> .
 */
@Library("avcodec") 
public class AVPacket extends StructObject {
	static {
		BridJ.register();
	}
	/**
	 * A reference to the reference-counted buffer where the packet data is<br>
	 * stored.<br>
	 * May be NULL, then the packet data is not reference-counted.<br>
	 * C type : AVBufferRef*
	 */
	@Field(0) 
	public Pointer<AVBufferRef > buf() {
		return this.io.getPointerField(this, 0);
	}
	/**
	 * A reference to the reference-counted buffer where the packet data is<br>
	 * stored.<br>
	 * May be NULL, then the packet data is not reference-counted.<br>
	 * C type : AVBufferRef*
	 */
	@Field(0) 
	public AVPacket buf(Pointer<AVBufferRef > buf) {
		this.io.setPointerField(this, 0, buf);
		return this;
	}
	/**
	 * Presentation timestamp in AVStream->time_base units; the time at which<br>
	 * the decompressed packet will be presented to the user.<br>
	 * Can be AV_NOPTS_VALUE if it is not stored in the file.<br>
	 * pts MUST be larger or equal to dts as presentation cannot happen before<br>
	 * decompression, unless one wants to view hex dumps. Some formats misuse<br>
	 * the terms dts and pts/cts to mean something different. Such timestamps<br>
	 * must be converted to true pts/dts before they are stored in AVPacket.
	 */
	@Alignment(4)
	@Field(1) 
	public long pts() {
		return this.io.getLongField(this, 1);
	}
	/**
	 * Presentation timestamp in AVStream->time_base units; the time at which<br>
	 * the decompressed packet will be presented to the user.<br>
	 * Can be AV_NOPTS_VALUE if it is not stored in the file.<br>
	 * pts MUST be larger or equal to dts as presentation cannot happen before<br>
	 * decompression, unless one wants to view hex dumps. Some formats misuse<br>
	 * the terms dts and pts/cts to mean something different. Such timestamps<br>
	 * must be converted to true pts/dts before they are stored in AVPacket.
	 */
	@Field(1) 
	public AVPacket pts(long pts) {
		this.io.setLongField(this, 1, pts);
		return this;
	}
	/**
	 * Decompression timestamp in AVStream->time_base units; the time at which<br>
	 * the packet is decompressed.<br>
	 * Can be AV_NOPTS_VALUE if it is not stored in the file.
	 */
	@Alignment(4)
	@Field(2) 
	public long dts() {
		return this.io.getLongField(this, 2);
	}
	/**
	 * Decompression timestamp in AVStream->time_base units; the time at which<br>
	 * the packet is decompressed.<br>
	 * Can be AV_NOPTS_VALUE if it is not stored in the file.
	 */
	@Field(2) 
	public AVPacket dts(long dts) {
		this.io.setLongField(this, 2, dts);
		return this;
	}
	/** C type : uint8_t* */
	@Field(3) 
	public Pointer<Byte > data() {
		return this.io.getPointerField(this, 3);
	}
	/** C type : uint8_t* */
	@Field(3) 
	public AVPacket data(Pointer<Byte > data) {
		this.io.setPointerField(this, 3, data);
		return this;
	}
	@Field(4) 
	public int size() {
		return this.io.getIntField(this, 4);
	}
	@Field(4) 
	public AVPacket size(int size) {
		this.io.setIntField(this, 4, size);
		return this;
	}
	@Field(5) 
	public int stream_index() {
		return this.io.getIntField(this, 5);
	}
	@Field(5) 
	public AVPacket stream_index(int stream_index) {
		this.io.setIntField(this, 5, stream_index);
		return this;
	}
	/** A combination of AV_PKT_FLAG values */
	@Field(6) 
	public int flags() {
		return this.io.getIntField(this, 6);
	}
	/** A combination of AV_PKT_FLAG values */
	@Field(6) 
	public AVPacket flags(int flags) {
		this.io.setIntField(this, 6, flags);
		return this;
	}
	/**
	 * Additional packet data that can be provided by the container.<br>
	 * Packet can contain several types of side information.<br>
	 * C type : AVPacketSideData*
	 */
	@Field(7) 
	public Pointer<AVPacketSideData > side_data() {
		return this.io.getPointerField(this, 7);
	}
	/**
	 * Additional packet data that can be provided by the container.<br>
	 * Packet can contain several types of side information.<br>
	 * C type : AVPacketSideData*
	 */
	@Field(7) 
	public AVPacket side_data(Pointer<AVPacketSideData > side_data) {
		this.io.setPointerField(this, 7, side_data);
		return this;
	}
	@Field(8) 
	public int side_data_elems() {
		return this.io.getIntField(this, 8);
	}
	@Field(8) 
	public AVPacket side_data_elems(int side_data_elems) {
		this.io.setIntField(this, 8, side_data_elems);
		return this;
	}
	/**
	 * Duration of this packet in AVStream->time_base units, 0 if unknown.<br>
	 * Equals next_pts - this_pts in presentation order.
	 */
	@Field(9) 
	public int duration() {
		return this.io.getIntField(this, 9);
	}
	/**
	 * Duration of this packet in AVStream->time_base units, 0 if unknown.<br>
	 * Equals next_pts - this_pts in presentation order.
	 */
	@Field(9) 
	public AVPacket duration(int duration) {
		this.io.setIntField(this, 9, duration);
		return this;
	}
	/** C type : destruct_callback* */
	@Field(10) 
	public Pointer<AVPacket.destruct_callback > destruct() {
		return this.io.getPointerField(this, 10);
	}
	/** C type : destruct_callback* */
	@Field(10) 
	public AVPacket destruct(Pointer<AVPacket.destruct_callback > destruct) {
		this.io.setPointerField(this, 10, destruct);
		return this;
	}
	/** C type : void* */
	@Field(11) 
	public Pointer<? > priv() {
		return this.io.getPointerField(this, 11);
	}
	/** C type : void* */
	@Field(11) 
	public AVPacket priv(Pointer<? > priv) {
		this.io.setPointerField(this, 11, priv);
		return this;
	}
	/** < byte position in stream, -1 if unknown */
	@Field(12) 
	public long pos() {
		return this.io.getLongField(this, 12);
	}
	/** < byte position in stream, -1 if unknown */
	@Field(12) 
	public AVPacket pos(long pos) {
		this.io.setLongField(this, 12, pos);
		return this;
	}
	/**
	 * Time difference in AVStream->time_base units from the pts of this<br>
	 * packet to the point at which the output from the decoder has converged<br>
	 * independent from the availability of previous frames. That is, the<br>
	 * frames are virtually identical no matter if decoding started from<br>
	 * the very first frame or from this keyframe.<br>
	 * Is AV_NOPTS_VALUE if unknown.<br>
	 * This field is not the display duration of the current packet.<br>
	 * This field has no meaning if the packet does not have AV_PKT_FLAG_KEY<br>
	 * set.<br>
	 * * The purpose of this field is to allow seeking in streams that have no<br>
	 * keyframes in the conventional sense. It corresponds to the<br>
	 * recovery point SEI in H.264 and match_time_delta in NUT. It is also<br>
	 * essential for some types of subtitle streams to ensure that all<br>
	 * subtitles are correctly displayed after seeking.
	 */
	@Field(13) 
	public long convergence_duration() {
		return this.io.getLongField(this, 13);
	}
	/**
	 * Time difference in AVStream->time_base units from the pts of this<br>
	 * packet to the point at which the output from the decoder has converged<br>
	 * independent from the availability of previous frames. That is, the<br>
	 * frames are virtually identical no matter if decoding started from<br>
	 * the very first frame or from this keyframe.<br>
	 * Is AV_NOPTS_VALUE if unknown.<br>
	 * This field is not the display duration of the current packet.<br>
	 * This field has no meaning if the packet does not have AV_PKT_FLAG_KEY<br>
	 * set.<br>
	 * * The purpose of this field is to allow seeking in streams that have no<br>
	 * keyframes in the conventional sense. It corresponds to the<br>
	 * recovery point SEI in H.264 and match_time_delta in NUT. It is also<br>
	 * essential for some types of subtitle streams to ensure that all<br>
	 * subtitles are correctly displayed after seeking.
	 */
	@Field(13) 
	public AVPacket convergence_duration(long convergence_duration) {
		this.io.setLongField(this, 13, convergence_duration);
		return this;
	}
	/** <i>native declaration : ./libavcodec/avcodec.h:326</i> */
	public static abstract class destruct_callback extends Callback<destruct_callback > {
		public void apply(Pointer<AVPacket > AVPacketPtr1) {
			apply(Pointer.getPeer(AVPacketPtr1));
		}
		public void apply(@Ptr long AVPacketPtr1) {
			apply(Pointer.pointerToAddress(AVPacketPtr1, AVPacket.class));
		}
	};
	@Struct(customizer=AlignmentCustomizer.class)
	public AVPacket() {
		super();
	}
	@Struct(customizer=AlignmentCustomizer.class)
	public AVPacket(Pointer pointer) {
		super(pointer);
	}
	public List<StructFieldDescription> getDescriptions() {
		return this.io.desc.getAggregatedFields();
	}
}
